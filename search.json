[
  {
    "objectID": "TCM/连续型机器学习模型.html",
    "href": "TCM/连续型机器学习模型.html",
    "title": "连续型机器学习模型",
    "section": "",
    "text": "✏️本节导读\n\n\n\n本节考虑到由于不同种类的蛋白质作用机制、作用通路差别较大，以及数据之间可能存在非线性关系，于是考虑机器学习模型来提升拟合优度。\n分别构建随机森林模型、梯度提升机模型、支持向量机模型，但效果并不理想，拟合优度仅有微弱提升。",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#处理自变量中存在的分类变量",
    "href": "TCM/连续型机器学习模型.html#处理自变量中存在的分类变量",
    "title": "连续型机器学习模型",
    "section": "处理自变量中存在的分类变量",
    "text": "处理自变量中存在的分类变量\n将分类变量进行独热编码并与原数据合并\n\n&gt; library(caret)\n&gt; dummy_vars &lt;- dummyVars(~ Species, data = EC50)  \n&gt;   \n&gt; # 使用predict函数和dummyVars对象来生成独热编码矩阵  \n&gt; \n&gt; dummy_data &lt;- predict(dummy_vars, newdata = EC50) \n&gt; dummy_EC50 &lt;- data.frame(dummy_data,EC50[,-1])",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#数据分割",
    "href": "TCM/连续型机器学习模型.html#数据分割",
    "title": "连续型机器学习模型",
    "section": "数据分割",
    "text": "数据分割\n\n&gt; library(caret)\n\n\n&gt; set.seed(1232)\n&gt; trainIndex &lt;- createDataPartition(dummy_EC50$log10ec50,times=1,p=0.8,list=FALSE,groups=min(10,length(EC50$log10ec50)))\n&gt; Train &lt;- dummy_EC50[trainIndex,]\n&gt; Test &lt;- dummy_EC50[-trainIndex,]",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#简单线性回归",
    "href": "TCM/连续型机器学习模型.html#简单线性回归",
    "title": "连续型机器学习模型",
    "section": "简单线性回归",
    "text": "简单线性回归\n\n&gt; library(easystats)\n&gt; model &lt;- lm(log10ec50~.-ec50,data = dummy_EC50)\n&gt; summary(model)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ . - ec50, data = dummy_EC50)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -3.12757 -0.57544  0.09198  0.71236  3.10667 \n   \n   Coefficients: (1 not defined because of singularities)\n                Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)  5.705250   0.894998   6.375 1.58e-09 ***\n   SpeciesALK  -0.215138   0.374173  -0.575  0.56605    \n   SpeciesFLA   1.002742   0.382097   2.624  0.00945 ** \n   SpeciesORG  -0.105390   0.450112  -0.234  0.81515    \n   SpeciesPHE   0.271202   0.406670   0.667  0.50572    \n   SpeciesPPP   0.839988   0.426249   1.971  0.05034 .  \n   SpeciesSAP   0.936018   0.409637   2.285  0.02351 *  \n   SpeciesSTE   0.387236   0.655961   0.590  0.55573    \n   SpeciesTER         NA         NA      NA       NA    \n   AKT1        -0.084454   0.149827  -0.564  0.57370    \n   PKC         -0.259246   0.179452  -1.445  0.15034    \n   PIK3CA       0.206708   0.165903   1.246  0.21445    \n   PDE5        -0.295592   0.176336  -1.676  0.09547 .  \n   AMPK        -0.005946   0.229171  -0.026  0.97933    \n   eNOS        -0.292342   0.144029  -2.030  0.04390 *  \n   SIRT1        0.136005   0.187839   0.724  0.47000    \n   PDK1        -0.017912   0.148210  -0.121  0.90395    \n   PRKG1        0.034131   0.184448   0.185  0.85341    \n   APLNR       -0.194230   0.206903  -0.939  0.34915    \n   TGR5         0.236086   0.153745   1.536  0.12645    \n   EDNRB       -0.032738   0.186231  -0.176  0.86066    \n   CYP1A1      -0.063554   0.063699  -0.998  0.31979    \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 1.141 on 175 degrees of freedom\n   Multiple R-squared:  0.2625, Adjusted R-squared:  0.1783 \n   F-statistic: 3.115 on 20 and 175 DF,  p-value: 2.969e-05\n\n\n最优子集回归\n\n&gt; model_final &lt;- model|&gt;\n+   select_parameters()\n&gt; summary(model_final)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ SpeciesFLA + SpeciesPPP + SpeciesSAP + \n       PKC + PDE5 + eNOS + TGR5, data = dummy_EC50)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -3.01670 -0.60264  0.07386  0.74992  2.94107 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)   5.4385     0.5905   9.211  &lt; 2e-16 ***\n   SpeciesFLA    0.8571     0.2315   3.702 0.000281 ***\n   SpeciesPPP    0.7651     0.3122   2.451 0.015176 *  \n   SpeciesSAP    0.8560     0.3152   2.716 0.007221 ** \n   PKC          -0.1911     0.1274  -1.500 0.135250    \n   PDE5         -0.2865     0.1164  -2.462 0.014708 *  \n   eNOS         -0.3019     0.1235  -2.444 0.015430 *  \n   TGR5          0.2179     0.1191   1.830 0.068822 .  \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 1.12 on 188 degrees of freedom\n   Multiple R-squared:  0.2356, Adjusted R-squared:  0.2071 \n   F-statistic: 8.277 on 7 and 188 DF,  p-value: 8.554e-09",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#训练数据",
    "href": "TCM/连续型机器学习模型.html#训练数据",
    "title": "连续型机器学习模型",
    "section": "训练数据",
    "text": "训练数据\n\n&gt; library(caret)\n&gt; #交叉验证\n&gt; fitControl &lt;- trainControl(method = \"repeatedcv\",number = 30,repeats = 3)",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#梯度提升机gbm",
    "href": "TCM/连续型机器学习模型.html#梯度提升机gbm",
    "title": "连续型机器学习模型",
    "section": "梯度提升机GBM",
    "text": "梯度提升机GBM\n\n&gt; set.seed(2024.11)\n&gt; gbmfit &lt;- train(log10ec50~.-ec50,data = Train,method = \"gbm\",trControl=fitControl,verbose=FALSE)\n&gt; gbmfit\n\n   Stochastic Gradient Boosting \n   \n   160 samples\n    22 predictor\n   \n   No pre-processing\n   Resampling: Cross-Validated (30 fold, repeated 3 times) \n   Summary of sample sizes: 154, 156, 155, 156, 154, 154, ... \n   Resampling results across tuning parameters:\n   \n     interaction.depth  n.trees  RMSE      Rsquared   MAE      \n     1                   50      1.133618  0.3638800  0.9001328\n     1                  100      1.163915  0.3527667  0.9207122\n     1                  150      1.179919  0.3430091  0.9338863\n     2                   50      1.153152  0.3295414  0.9128672\n     2                  100      1.186039  0.3248243  0.9330707\n     2                  150      1.212259  0.3041567  0.9558360\n     3                   50      1.168970  0.3279048  0.9264794\n     3                  100      1.205238  0.3136124  0.9623404\n     3                  150      1.229551  0.3231229  0.9803674\n   \n   Tuning parameter 'shrinkage' was held constant at a value of 0.1\n   \n   Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n   RMSE was used to select the optimal model using the smallest value.\n   The final values used for the model were n.trees = 50, interaction.depth =\n    1, shrinkage = 0.1 and n.minobsinnode = 10.",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#随机森林random-forest",
    "href": "TCM/连续型机器学习模型.html#随机森林random-forest",
    "title": "连续型机器学习模型",
    "section": "随机森林Random Forest",
    "text": "随机森林Random Forest\n\n&gt; library(randomForest)\n&gt; set.seed(2024)\n&gt; rffit &lt;- train(log10ec50~.-ec50,data = Train,method = \"rf\",trControl=fitControl,verbose=FALSE)\n&gt; rffit\n\n   Random Forest \n   \n   160 samples\n    22 predictor\n   \n   No pre-processing\n   Resampling: Cross-Validated (30 fold, repeated 3 times) \n   Summary of sample sizes: 154, 156, 155, 156, 154, 154, ... \n   Resampling results across tuning parameters:\n   \n     mtry  RMSE      Rsquared   MAE      \n      2    1.128893  0.3765522  0.8927256\n     11    1.163318  0.3481787  0.9170471\n     21    1.178710  0.3250263  0.9296655\n   \n   RMSE was used to select the optimal model using the smallest value.\n   The final value used for the model was mtry = 2.",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#支持向量机svm",
    "href": "TCM/连续型机器学习模型.html#支持向量机svm",
    "title": "连续型机器学习模型",
    "section": "支持向量机SVM",
    "text": "支持向量机SVM\n\n&gt; library(kernlab)\n&gt; tuneGrid1 &lt;- expand.grid(C = 2^(-2:5), sigma = c(0.01, 0.1, 1)) \n&gt; set.seed(2024.13)\n&gt; svmfit &lt;- train(log10ec50~.-ec50,data = Train,method = \"svmRadial\",trControl=fitControl,verbose=FALSE,tuneGrid= tuneGrid1) \n&gt; svmfit\n\n   Support Vector Machines with Radial Basis Function Kernel \n   \n   160 samples\n    22 predictor\n   \n   No pre-processing\n   Resampling: Cross-Validated (30 fold, repeated 3 times) \n   Summary of sample sizes: 154, 156, 155, 156, 154, 154, ... \n   Resampling results across tuning parameters:\n   \n     C      sigma  RMSE      Rsquared   MAE      \n      0.25  0.01   1.114817  0.3290295  0.8840081\n      0.25  0.10   1.126874  0.2728372  0.8864627\n      0.25  1.00   1.145490  0.2866486  0.9093973\n      0.50  0.01   1.106094  0.3250227  0.8731409\n      0.50  0.10   1.144269  0.2806425  0.8968490\n      0.50  1.00   1.128325  0.2933209  0.8884422\n      1.00  0.01   1.108713  0.3299019  0.8727065\n      1.00  0.10   1.201813  0.2793701  0.9501702\n      1.00  1.00   1.132500  0.3130900  0.8877241\n      2.00  0.01   1.125001  0.3081330  0.8877209\n      2.00  0.10   1.232938  0.2831844  0.9764720\n      2.00  1.00   1.143035  0.3033660  0.8962083\n      4.00  0.01   1.156479  0.2866684  0.9166405\n      4.00  0.10   1.244790  0.2796459  0.9853496\n      4.00  1.00   1.152324  0.2965280  0.9048406\n      8.00  0.01   1.168273  0.3080343  0.9274460\n      8.00  0.10   1.289098  0.2854485  1.0250625\n      8.00  1.00   1.152679  0.2960620  0.9050780\n     16.00  0.01   1.199418  0.3120593  0.9577236\n     16.00  0.10   1.307431  0.2957023  1.0449073\n     16.00  1.00   1.152679  0.2960620  0.9050780\n     32.00  0.01   1.265304  0.2974215  1.0119017\n     32.00  0.10   1.319630  0.2959489  1.0526886\n     32.00  1.00   1.152679  0.2960620  0.9050780\n   \n   RMSE was used to select the optimal model using the smallest value.\n   The final values used for the model were sigma = 0.01 and C = 0.5.",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#比较几种方法的预测效果",
    "href": "TCM/连续型机器学习模型.html#比较几种方法的预测效果",
    "title": "连续型机器学习模型",
    "section": "比较几种方法的预测效果",
    "text": "比较几种方法的预测效果",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#均方误差mse",
    "href": "TCM/连续型机器学习模型.html#均方误差mse",
    "title": "连续型机器学习模型",
    "section": "均方误差MSE",
    "text": "均方误差MSE\n\n&gt; MSE &lt;- function(model,Test){\n+     predict &lt;- predict(model,newdata = Test)\n+     real &lt;- Test$log10ec50\n+     # 计算MSE\n+     mse_lm &lt;- mean((predict - real)^2)\n+     print(paste(\" MSE:\", mse_lm))\n+     sst &lt;-sum((real-mean(real))^2)\n+     sse &lt;- sum((predict-real)^2)\n+     rsq &lt;-1-sse/sst\n+     print(paste(\"R-square:\", rsq))\n+ }\n\n\n&gt; MSE(rffit,Test)\n\n   [1] \" MSE: 1.38425553942827\"\n   [1] \"R-square: 0.122646283157883\"\n\n&gt; MSE(svmfit,Test)\n\n   [1] \" MSE: 1.35111843953737\"\n   [1] \"R-square: 0.143648877640301\"\n\n&gt; MSE(gbmfit,Test)\n\n   [1] \" MSE: 1.41067131279206\"\n   [1] \"R-square: 0.10590372639445\"",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/连续型机器学习模型.html#预测",
    "href": "TCM/连续型机器学习模型.html#预测",
    "title": "连续型机器学习模型",
    "section": "预测",
    "text": "预测\n下面显示的表格的最后三列即为三种机器学习方法的预测结果。\n\n&gt; rffit_predict &lt;- predict(rffit,newdata = saponin_predict_all)\n&gt; svmfit_predict &lt;- predict(svmfit,newdata = saponin_predict_all)\n&gt; gbmfit_predict &lt;- predict(gbmfit,newdata = saponin_predict_all)\n\n\n&gt; saponin_predict_all &lt;- cbind(saponin_predict_all,rffit_predict,svmfit_predict,gbmfit_predict)\n&gt; saponin_predict_all &lt;- as.data.frame(saponin_predict_all)\n&gt; saponin_predict_all[10,]\n\n      SpeciesALK SpeciesFLA SpeciesORG SpeciesPHE SpeciesPPP SpeciesSAP SpeciesSTE\n   10          1          0          0          0          0          0          0\n      SpeciesTER  AKT1   PKC PIK3CA PDE5  AMPK  eNOS SIRT1  PDK1 PRKG1 APLNR  TGR5\n   10          0 5.974 7.517   7.81 9.12 9.372 8.101 9.978 9.131 6.715  7.72 9.659\n      EDNRB CYP1A1 rffit_predict svmfit_predict gbmfit_predict\n   10  7.67  6.149      1.739291       0.929666        1.52114\n\n\n作图展示预测结果\n\n&gt; Comparation &lt;- data.frame(randomForest = rffit_predict , SVM = svmfit_predict,GBM = gbmfit_predict,number = factor(c(1:length(rffit_predict)))) |&gt;\n+   melt(id.vars = \"number\")\n&gt; ggplot(Comparation, aes(x=number,y = value,color = variable,group=variable))+\n+   geom_point(aes(shape=variable),size=2)+\n+   geom_line(lwd=1)+theme_classic()+\n+   theme(axis.text.x = element_blank())+ # 去掉X轴刻度标签\n+   labs(title = \"Comparation between different predict values\")",
    "crumbs": [
      "中医药研究TCM",
      "连续型机器学习模型"
    ]
  },
  {
    "objectID": "TCM/二分类机器学习模型.html",
    "href": "TCM/二分类机器学习模型.html",
    "title": "二分类机器学习模型",
    "section": "",
    "text": "✏️本节导读\n\n\n\n本节首先根据因变量ec50的取值大小将因变量转化为二分类变量；ec50&lt;=300认为可能存在舒张血管的活性，记为“1”，反之认为没有舒张血管活性，记为“0”。\n在boostrap抽样和网格调参的基础上构建机器学习模型——随机森林、支持向量机、梯度提升机，最终选取随机森林模型作为最优模型，准确率达到0.875，ROC曲线下面积达到0.891。",
    "crumbs": [
      "中医药研究TCM",
      "二分类机器学习模型"
    ]
  },
  {
    "objectID": "TCM/二分类机器学习模型.html#交叉验证法与自助法",
    "href": "TCM/二分类机器学习模型.html#交叉验证法与自助法",
    "title": "二分类机器学习模型",
    "section": "交叉验证法与自助法",
    "text": "交叉验证法与自助法\n\n&gt; #重复3次的10折交叉验证\n&gt; fitControl1 &lt;- trainControl(method = \"repeatedcv\",number = 10,repeats = 3)\n&gt; #自助法抽样\n&gt; fitControl5 &lt;- trainControl(method = \"boot632\",repeats = 3)\n\n在R语言的caret包中，trainControl函数是用来控制训练过程的各种参数的，其中method参数指定了交叉验证或自助法（bootstrap）的具体方法。method参数值的解释：\n“boot632”: 指的是.632自助法（bootstrap），也称为.632+自助法的一个简化版本（不计算偏差校正项）。这种方法通过自助法生成多个训练集，并在这些训练集上评估模型，同时使用未用于训练的原始数据部分来估计模型的性能。这种方法旨在减少过拟合导致的性能高估。。\n“repeatedcv”: 表示重复交叉验证。这种方法通过多次执行交叉验证（每次重新划分数据集），然后取结果的平均值，来减少因单次交叉验证划分不当导致的性能估计偏差。",
    "crumbs": [
      "中医药研究TCM",
      "二分类机器学习模型"
    ]
  },
  {
    "objectID": "TCM/二分类机器学习模型.html#决策树",
    "href": "TCM/二分类机器学习模型.html#决策树",
    "title": "二分类机器学习模型",
    "section": "决策树",
    "text": "决策树\n\n&gt; library(rpart)\n&gt; library(rpart.plot)\n&gt; # 构建决策树模型\n&gt; model1 &lt;- rpart(result ~.-ec50, data = EC50_sp)\n&gt; # 绘制决策树路径图\n&gt; rpart.plot(model1)\n\n\n\n\n\n\n\n\n\n&gt; model2 &lt;- rpart(result ~.-ec50, data = Train1)\n&gt; # 绘制决策树路径图\n&gt; rpart.plot(model2)\n\n\n\n\n\n\n\n\n\n&gt; predictions &lt;- predict(model2,Test1,type = \"class\")\n&gt; library(e1071)\n&gt; confusionMatrix(predictions,Test1$result)\n\n   Confusion Matrix and Statistics\n   \n             Reference\n   Prediction  0  1\n            0  6  1\n            1  5 36\n                                             \n                  Accuracy : 0.875           \n                    95% CI : (0.7475, 0.9527)\n       No Information Rate : 0.7708          \n       P-Value [Acc &gt; NIR] : 0.05453         \n                                             \n                     Kappa : 0.5944          \n                                             \n    Mcnemar's Test P-Value : 0.22067         \n                                             \n               Sensitivity : 0.5455          \n               Specificity : 0.9730          \n            Pos Pred Value : 0.8571          \n            Neg Pred Value : 0.8780          \n                Prevalence : 0.2292          \n            Detection Rate : 0.1250          \n      Detection Prevalence : 0.1458          \n         Balanced Accuracy : 0.7592          \n                                             \n          'Positive' Class : 0",
    "crumbs": [
      "中医药研究TCM",
      "二分类机器学习模型"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "欢迎来到杨文灿的成果展",
    "section": "",
    "text": "个人简介\n杨文灿，女，天津中医药大学 公共卫生与健康科学学院 应用统计学。\n主修课程：多元统计分析97、应用回归分析97、非参数统计94、数理统计学97、生物统计学94、\n数学分析91、概率论96、高等代数95、线性统计模型96、R软件与计算95、C语言程序设计96、\nPython程序设计92、数据库原理95、SAS统计软件（在学）、时间序列分析（在学）等。\n绩点(GPA)：4.126/5.0 排名：1/48\n综合成绩排名(综测)：1/48\n\n\n获奖经历\n\n\n\n\n\n\n相关荣誉\n\n\n\n2023年4月 全国市场调查与分析大赛市级三等奖\n2023年5月 锐思杯”数据建模大赛市级优胜奖\n2023年10月 第二届高校数据科学大赛二等奖\n2023年10月 获得国家励志奖学金、校级一等奖学金\n2023年12月 获得“三好学生”荣誉称号\n2024年4月 全国市场调查与分析大赛市级一等奖\n2024年5月 校级大学生创新创业计划项目立项\n2024年7月 一篇学术论文收录于在中国生物统计学术会议\n2024年8月 第十届统计建模大赛市级三等奖\n2024年9月 “挑战杯”中国大学生创业计划竞赛市级铜奖\n2024年10月 第一届大学生数据要素素质大赛优秀奖\n2024年12月 获得天津市中银奖学金、校级一等奖学金\n\n\n\n\n实践经历\n2023.06-2023.08 在天津中医药大学第四附属医院实习\n\n参与肛肠科的天津市居民肛肠健康调研；\n参与调查问卷的编写和修改；\n在天津市各医院进行线下问卷收集。\n\n2024.06-2024.08 在天津市肿瘤医院实习，担任小组长\n\n了解医院临床试验机构的药物存储流程；\n学习临床数据的处理分析方法和R语言程序；\n参加医院临床一期临床医疗数据来源以及处理流程。\n\n\n\n个人技能\n\n语言能力：通过英语六级笔试；六级口语等级为优秀；\n计算机能力：通过全国计算机等级考试（二级）；\n编程能力：熟练掌握R语言、Python、C等编程语言；\n统计能力：熟练使用SPSS、Rstudio、PyCharm、VS Code、MATLAB等编程软件，正在学习SAS。\n\n\n\n科研经历\n2023.10~2024.03 参与课题-中国式现代化背景下天津市公共医疗体制机制创新研究\n\n在课题中主要收集近10年的医疗数据；\n查阅国内外的医疗政策与相关文献，并与天津市现有政策进行对比；\n撰写相关文献综述，为课题研究的理论构建提供参考依据。\n\n2024.07~目前 参与课题-基于机器学习的天然血管保护剂的理论预测和筛选方法构建及应用\n\n在课题中担任模型构建小组的组长，主要任务是构建机器学习模型，使用蛋白化合物与十三个靶点蛋白的结合能预测log10ec5值，进而判断该蛋白化合物舒张血管的作用的强弱。\n同时使用R和Python语言建模，在交叉验证和网格调参的基础上构建的二分类模型包括随机森林RF、支持向量机SVM、梯度提升机GBM，表现最优的是随机森林模型，准确率达到0.875，AUC值0.891。\n\n\n\n网站简介\n接下来，这个网站将会向您展示我的科研成果，包括我研究的主题，探索的过程，构建的模型以及取得的成果。\n\n\n\n\n\n\n目录\n\n\n\n第一章 nycflights13包中航班延误数据的探索\n• 第一节 本章目录\n• 第二节 flights数据集探索\n• 第三节 weather数据集探索\n• 第四节 联立两个数据集\n• 第五节 weather数据集重探索\n• 第六节 线性回归模型\n• 第七节 机器学习模型\n第二章 中医药数据机器学习模型构建\n• 第一节 本章目录\n• 第二节 线性回归模型\n• 第三节 连续型机器学习模型\n• 第四节 二分类机器学习模型",
    "crumbs": [
      "个人简介"
    ]
  },
  {
    "objectID": "EDA/reweather.html",
    "href": "EDA/reweather.html",
    "title": "Weather数据集重探索",
    "section": "",
    "text": "🍀本节导读\n\n\n\n在本节对于合并后的数据集joined_data（既包含天气数据又包含航班数据）进行了重新探索，探索天气各变量与航班延误的关系。\n与别于第三小节探究weather数据集中各变量的关系，本节是探究天气各变量与arr_delay之间的关系。\n在本节发现了散点图中存在的一些问题~请看详细谈论🚡\n\n\nweather数据集中的变量有：\ntemp, dewp：温度和露点温度，以华氏度为单位。\nhumid：相对湿度。\nwind_dir, wind_speed：风向（以度为单位）、风速，以英里每小时为单位。\nprecip：降水量，以英寸为单位。\npressure：海平面气压，以毫巴为单位。\nvisib：能见度，以英里为单位。\n\n降水量(precip)与航班延误的关系\n\n&gt; joined_data |&gt;   \n+   ggplot(aes(x= precip,y = arr_delay))+  \n+   geom_point(aes(color = origin))+   \n+   theme_bw()\n\n\n\n\n\n\n\n\n从这张散点图得到的信息，似乎降水量越大，反而延误的航班少，给人一种：乍一看二者是负相关的感觉，与我们的常识相反。\n然后我做了一张密度图重新观察二者的关系，按照降水量不同来呈现颜色深浅。\n\n&gt; ggplot(joined_data, aes(x = arr_delay, group = precip, color = precip)) +\n+   geom_density()\n\n\n\n\n\n\n\n\n从这张图中，我们可以看到，降水量少时，航班延误在0中心波动，近似呈现对称的钟形，但是随着降水量的增大（即颜色变深），曲线的中心逐渐右移（增大），因此我们可以简单得出结论，降水量与航班延误确实有正相关的关系，但是由于在降水量较大时，航班数量较少，因此波动较小降水量较小时，航班数量较多，数据波动较大，因此散点图上呈现出一种类似负相关的误解。\n\n\n能见度(visib)与航班延误的关系\n\n&gt; joined_data |&gt;\n+   ggplot(aes(x= factor(visib),y = arr_delay))+\n+   geom_boxplot(color = \"#D3AE7C\")+\n+   theme_classic()\n\n\n\n\n\n\n\n\n从箱线图中可以看出，能见度小于2时，航班延误的中心位置较高，随着能见度的增加，延误的中心值在降低，数据分布也更为集中，因此我们简单认为能见度与航班延误呈现负相关。\n\n&gt; joined_data |&gt;\n+   ggplot(aes(x= factor(visib)))+\n+   geom_bar(fill= \"#D3AE7C\")+\n+   theme_bw()\n\n\n\n\n\n\n\n\n这张频率柱形图揭示了以上为什么能见度高时，航班延误的异常值很多，因为能见度高时航班的出行班次较多（25万多次航班），因此正态分布的数据位于两侧的异常情况虽然概率较小，但也一定会发生，且次数不少。因此如果使用散点图可能会带给我们一些错觉，而由于visib的值较为分散，因此直接看成分类类型的数据做箱线图比较直观地反映出了数据的集中趋势，避免了上述问题。\n\n\n风速(wind_speed)与航班延误的关系\n\n&gt; joined_data |&gt;\n+   ggplot(aes(x= wind_speed,y = arr_delay))+\n+   geom_point(aes(color = origin))+\n+   geom_smooth(method = \"lm\",color = \"red\")+\n+   theme_bw()\n\n\n\n\n\n\n\n\n对所有的数据做散点图发现风速与航班延误没有什么关系，而且风速越大，好像延误的值更小一些，那是不是视觉上的偏误呢？\n\n&gt; joined_data |&gt;\n+   ggplot(aes(x= wind_speed))+\n+   geom_bar(fill= \"#D3AE7C\",alpha = 0.8)+\n+   theme_bw()\n\n\n\n\n\n\n\n\n接着，对风速做直方图，发现不同风速的航班数的分布与上图风速与航班延误的分布有些相似，因此初步怀疑，是航班数量不同造成的影响。 为了减弱航班数量的影响，我写了一个函数来将风速（自变量）进行分层，并在每一层（每一段取值范围中）随机抽取一些点，构成新的数据集，使用新的数据集进行作图，我们看看效果：\n\n&gt; Sample &lt;- function(variable){\n+   laying &lt;- joined_data |&gt;\n+   mutate(level = cut(variable, breaks = unique(quantile(variable, probs = seq(0, 1, 0.01))), include.lowest = TRUE))\n+   sample_size &lt;- 60 # 每个层次的样本量\n+   stratified_sample &lt;- laying |&gt;\n+     group_by(level) |&gt;\n+     sample_n(size = sample_size)\n+   return(stratified_sample)\n+ }\n\n\n&gt; sample1 &lt;- Sample(joined_data$wind_speed)\n&gt; sample1 |&gt;\n+   ggplot(aes(x= wind_speed,y = arr_delay))+\n+   geom_point(aes(color = origin))+\n+   geom_smooth(method = \"lm\",color = \"red\")+\n+   theme_bw()\n\n\n\n\n\n\n\n\n此时再作图，便可以看到微弱的正相关关系。\n\n\n\n\n\n\nQ4简单的散点图并不能反映出变量与航班延误之间的关系，如何解决？\n\n\n\n因为在散点图中可能受到不同值对应的航班飞行数目有较大差异，离散程度不同，因此可能会对航班延误之间的散点图造成一定的视觉偏差，应该如何处理？\n数据重采样技术：\n\n使用自助法（Bootstrap）对数据进行重采样，使得不同降水量下的样本量在多次抽样中保持相对均衡，从而减少样本量差异对结果的影响。\n分层抽样，根据降水量的不同水平进行分层，然后从每个层中抽取相同数量的样本。（本次采用分层抽样的思路来解决该问题）\n\n因此，对于一下数据的分析，都会先经过分层的重抽样，再讨论二者之间的关系。🤩\n\n\n\n\n温度与航班延误的关系\n\n&gt; sample1 &lt;- Sample(joined_data$temp)\n&gt; sample1 |&gt;\n+   ggplot(aes(x= temp,y = arr_delay))+\n+   geom_point(aes(color = origin),shape = 6)+\n+   facet_grid(origin ~ .)+\n+   theme_bw()+\n+   theme(strip.background = element_rect(colour = \"grey30\", fill = \"#D3AE7C\"))\n\n\n\n\n\n\n\n\n温度对航班的影响较为微弱，且三个地区的差别不太大，但似乎，在LGA地区温度与延误有微弱的正相关，但可能源于抽样误差。\n\n\n露点温度与航班延误的关系\n\n&gt; sample1 &lt;- Sample(joined_data$dewp)\n&gt; sample1 |&gt;\n+   ggplot(aes(x= dewp,y = arr_delay))+\n+   geom_point(aes(color = origin),shape = 5)+\n+   facet_grid(origin ~ .)+\n+   theme_bw()+\n+   theme(strip.background = element_rect(colour = \"grey30\", fill = \"#D3AE7C\"))\n\n\n\n\n\n\n\n\n露点温度对航班的影响较为微弱，且三个地区的差别不太大。\n\n\n湿度与航班延误的关系\n\n&gt; sample1 &lt;- Sample(joined_data$humid)\n&gt; sample1 |&gt;\n+   ggplot(aes(x= humid,y = arr_delay))+\n+   geom_point(aes(color = origin),shape = 6)+\n+   facet_grid(origin ~ .)+\n+   theme_bw()+\n+   theme(strip.background = element_rect(colour = \"grey30\", fill = \"#D3AE7C\"))\n\n\n\n\n\n\n\n\n湿度对航班的影响较为微弱，没有显著的关系。\n\n\n风向与航班延误的关系\n\n&gt; sample1 &lt;- Sample(joined_data$wind_dir)\n&gt; sample1 |&gt;\n+   ggplot(aes(x= wind_dir,y = arr_delay))+\n+   geom_point(aes(color = origin),alpha = 0.5)+\n+   facet_grid(~origin )+\n+   theme_bw()+\n+   theme(strip.background = element_rect(colour = \"grey30\", fill = \"#D3AE7C\"))\n\n\n\n\n\n\n\n\n风向对航班的影响也较为微弱，且三个地区的差别不太大。\n\n\n气压与航班延误的关系\n\n&gt; sample1 &lt;- Sample(joined_data$pressure)\n&gt; sample1 |&gt; \n+   ggplot(aes(x = pressure, y = arr_delay)) +\n+   geom_hex(bins = 30, color = \"grey35\") +\n+   theme_light() +\n+   labs(x = \"Pressure\", y = \"Arr_delay\", title = \"Hive Plot\",\n+        subtitle = \"Scatter Plot\") +\n+   scale_fill_gradient2(low = colorsEarth[5], mid = colorsEarth[2], high = colorsEarth[1],\n+                         midpoint = 8)\n\n\n\n\n\n\n\n\n从蜂巢图中可以看出，航班起飞在气压1005-1030之间较多，没有明显的线性关系。",
    "crumbs": [
      "nycflights13数据探索EDA",
      "Weather数据集重探索"
    ]
  },
  {
    "objectID": "EDA/joined_data.html",
    "href": "EDA/joined_data.html",
    "title": "联立两个数据集",
    "section": "",
    "text": "⌛本节导读\n\n\n\n将flights数据集与weather数据集进行合并，并对合并后数据集中的缺失值等进行处理，方面后续分析。\n这一部分实际上相当于Understand循环步骤中的transform步骤。放在Visulize之后，因为，本研究是基于两个数据集的探索，因此需要首先对于各个数据集做一个探索之后再进行合并，之后再次进行数据可视化。\n其实，这两步骤之间也存在一定的循环迭代关系，可视化可以帮助我们更好地了解数据，进而帮助数据变形这一过程。\n\n\n\n联立两个数据集\n经过对两个数据集的探索，我们大致了解了变量之间的关系，接下来，为了实现同时构建线性模型，我们需要将两个数据集进行整合。根据”origin”,“year”,“month”,“day”,“hour”这几个变量进行整合，使得数据集中同时具有该地出发的航班的信息，又有该地每日每时的天气信息。\n\n&gt; # 加载必要的包\n&gt; library(dplyr)\n&gt; library(nycflights13)\n&gt; \n&gt; # 加载数据集\n&gt; flights_data &lt;- flights\n&gt; weather_data &lt;- weather\n&gt; \n&gt; # 使用 inner_join 进行联立\n&gt; joined_data &lt;- inner_join(flights_data, weather_data, by = c(\"origin\",\"year\",\"month\",\"day\",\"hour\"))\n&gt; \n&gt; # 查看联立后的数据\n&gt; joined_data\n   # A tibble: 335,220 × 29\n       year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n      &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n    1  2013     1     1      517            515         2      830            819\n    2  2013     1     1      533            529         4      850            830\n    3  2013     1     1      542            540         2      923            850\n    4  2013     1     1      544            545        -1     1004           1022\n    5  2013     1     1      554            600        -6      812            837\n    6  2013     1     1      554            558        -4      740            728\n    7  2013     1     1      555            600        -5      913            854\n    8  2013     1     1      557            600        -3      709            723\n    9  2013     1     1      557            600        -3      838            846\n   10  2013     1     1      558            600        -2      753            745\n   # ℹ 335,210 more rows\n   # ℹ 21 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n   #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n   #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour.x &lt;dttm&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;,\n   #   humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;, wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;,\n   #   precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour.y &lt;dttm&gt;\n\n\n\n\n\n\n\nQ3 为什么联立后的数据变少了？\n\n\n\n发现，联立后的数据样本信息比flights原始数据集少一千多条，接下来，探究其原因\n\n\n（此处借用一下老师的查找缺失值的函数）\n\n&gt; library(YangPac)\n&gt; Missing(flights)\n\n\n\n\n\n\n\n&gt; Missing(weather)\n\n\n\n\n\n\n\n\n首先对缺失值进行检验，发现，我们的联立变量在两个数据集中均没有缺失。接着，考虑时间维度。\n\n&gt; #联立后数据\n&gt; A  &lt;- joined_data |&gt;\n+   arrange(year,month,day,hour)\n&gt; A[335220,]\n   # A tibble: 1 × 29\n      year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n     &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n   1  2013    12    30     2141           1815       206        2           2041\n   # ℹ 21 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n   #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n   #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour.x &lt;dttm&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;,\n   #   humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;, wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;,\n   #   precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour.y &lt;dttm&gt;\n&gt; # flights数据集\n&gt; B&lt;- flights|&gt;\n+   arrange(year,month,day,hour)\n&gt; B[336776,]\n   # A tibble: 1 × 19\n      year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n     &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n   1  2013    12    31     2356           2359        -3      436            445\n   # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n   #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n   #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n&gt; # 天气数据集\n&gt; C &lt;- weather|&gt;\n+   arrange(year,month,day,hour)\n&gt; C[26115,]\n   # A tibble: 1 × 15\n     origin  year month   day  hour  temp  dewp humid wind_dir wind_speed wind_gust\n     &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n   1 LGA     2013    12    30    18  28.9  10.9  46.4      330       18.4        NA\n   # ℹ 4 more variables: precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;,\n   #   time_hour &lt;dttm&gt;\n\n通过对各个数据集按时间排序后，调出最后一条数据，进行比较，发现，天气数据集中仅仅到12月30日18时，而18时之后以及31日的天气数据没有包含在天气数据集中，而flights数据集中有一千多条数据在这部分时间。由于这一天的一千多条的数据缺失对我们33万多条数据来说影响不大，因此不做考虑。\n首先浏览一下我们的数据集。\n\n&gt; glimpse(joined_data)\n   Rows: 335,220\n   Columns: 29\n   $ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n   $ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n   $ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n   $ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n   $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n   $ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n   $ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n   $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n   $ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n   $ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n   $ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n   $ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n   $ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n   $ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n   $ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n   $ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n   $ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n   $ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n   $ time_hour.x    &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…\n   $ temp           &lt;dbl&gt; 39.02, 39.92, 39.02, 39.02, 39.92, 39.02, 37.94, 39.92,…\n   $ dewp           &lt;dbl&gt; 28.04, 24.98, 26.96, 26.96, 24.98, 28.04, 28.04, 24.98,…\n   $ humid          &lt;dbl&gt; 64.43, 54.81, 61.63, 61.63, 54.81, 64.43, 67.21, 54.81,…\n   $ wind_dir       &lt;dbl&gt; 260, 250, 260, 260, 260, 260, 240, 260, 260, 260, 260, …\n   $ wind_speed     &lt;dbl&gt; 12.65858, 14.96014, 14.96014, 14.96014, 16.11092, 12.65…\n   $ wind_gust      &lt;dbl&gt; NA, 21.86482, NA, NA, 23.01560, NA, NA, 23.01560, NA, 2…\n   $ precip         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n   $ pressure       &lt;dbl&gt; 1011.9, 1011.4, 1012.1, 1012.1, 1011.7, 1011.9, 1012.4,…\n   $ visib          &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n   $ time_hour.y    &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…\n\n\n\n对于缺失值的处理\n\n&gt; Missing(joined_data)\n\n\n\n\n\n\n\n\n发现缺失值较多，多集中在wind_gust这个变量上，因此删除该变量，之后删除剩下数据集中包含缺失值的行。\n\n&gt; joined_data &lt;- na.omit(joined_data[,-25])\n&gt; Missing(joined_data)\n\n\n\n\n\n\n\n\n将处理好的数据导出到EXCEL表中，方便后续统计分析使用。\n\n&gt; library(writexl)\n&gt; write_xlsx(joined_data, \"joined_data.xlsx\")",
    "crumbs": [
      "nycflights13数据探索EDA",
      "联立两个数据集"
    ]
  },
  {
    "objectID": "EDA/contents.html",
    "href": "EDA/contents.html",
    "title": "探索航班延误的原因",
    "section": "",
    "text": "思路简介\n\n\n\n\n首先我对于nycflights13包中的flights数据集和weather数据集做了初步的数据探索性分析，了解各变量之间的关系。\n将两个数据集联立，对联立后的数据做一定的预处理，使得数据集完整，干净。\n之后重现探索weather数据集中的变量与arr_delay之间的关系。\n使用一般线性模型的方法构建模型R2值达到0.89。\n之后由临界点arr_delay=0为临界点，大于0视为延迟，小于0为正常抵达。以这个规则将连续型的目标变量划转化成二分类的变量。\n在使用5折交叉验证的基础上构建机器学习模型进行预测。精确程度达到0.8，但仍有提升的空间。\n\n\n\n\n\n\n\n\n\n✍️目录\n\n\n\n\nflights数据集探索\nweather数据集探索\n合并两个数据集\nweather数据重探索\n线性回归模型\n机器学习\n\n✈️ Let’s go on!",
    "crumbs": [
      "nycflights13数据探索EDA",
      "探索航班延误的原因"
    ]
  },
  {
    "objectID": "EDA/about.html",
    "href": "EDA/about.html",
    "title": "机器学习模型",
    "section": "",
    "text": "🔚本节导读\n\n\n\n在本章对于前几节处理好的数据建立机器学习模型（引入Python语言）。\n筛选好的解释变量纳入模型的构建，以arr_delay=0为界限划分被解释变量，使其成为二分类变量result，（使用二分类变量是因为二分类变量在结果解读和应用方面更简单，而且可以做出比较权威的ROC曲线图）。\n之后以8:2的比例划分训练集和测试集，并使用基于网格调参的5折交叉验证的方法训练模型。\n最后将模型用于测试集预测，评价模型在测试集上的表现。\n绘制ROC曲线得到曲线下面积AUC，综合评估模型性能。\n\n\n在本章，已经尝试了多种机器学习方法，但由于数据量很大，但计算机资源有限，因此这里只展示了目前训练较好的模型和最好的参数选择。\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n\n载入数据\n\nCare_data = pd.read_excel(\"D:\\\\Rstudio\\\\Rmyfile\\\\Flights\\\\select_data.xlsx\")\nprint(f\"Number of rows: {Care_data.shape[0]}, Number of columns: {Care_data.shape[1]}\")\nprint(Care_data)\nprint('数据载入完毕============================================1')\n\nNumber of rows: 284550, Number of columns: 20\n        month  day  dep_time  sched_dep_time  dep_delay  sched_arr_time  \\\n0           1    1       517             515          2             819   \n1           1    1       533             529          4             830   \n2           1    1       542             540          2             850   \n3           1    1       544             545         -1            1022   \n4           1    1       554             600         -6             837   \n...       ...  ...       ...             ...        ...             ...   \n284545      9   30      2240            2245         -5            2351   \n284546      9   30      2240            2250        -10               7   \n284547      9   30      2241            2246         -5               1   \n284548      9   30      2307            2255         12            2358   \n284549      9   30      2349            2359        -10             350   \n\n        arr_delay carrier origin dest  air_time  distance  hour   temp  humid  \\\n0              11      UA    EWR  IAH       227      1400     5  39.02  64.43   \n1              20      UA    LGA  IAH       227      1416     5  39.92  54.81   \n2              33      AA    JFK  MIA       160      1089     5  39.02  61.63   \n3             -18      B6    JFK  BQN       183      1576     5  39.02  61.63   \n4             -25      DL    LGA  ATL       116       762     6  39.92  54.81   \n...           ...     ...    ...  ...       ...       ...   ...    ...    ...   \n284545        -17      B6    JFK  SYR        41       209    22  60.98  83.47   \n284546        -20      B6    JFK  BUF        52       301    22  60.98  83.47   \n284547        -16      B6    JFK  ROC        47       264    22  60.98  83.47   \n284548          1      B6    JFK  BOS        33       187    22  60.98  83.47   \n284549        -25      B6    JFK  PSE       196      1617    23  60.08  83.41   \n\n        wind_dir  wind_speed  precip  pressure  visib  \n0            260    12.65858     0.0    1011.9   10.0  \n1            250    14.96014     0.0    1011.4   10.0  \n2            260    14.96014     0.0    1012.1   10.0  \n3            260    14.96014     0.0    1012.1   10.0  \n4            260    16.11092     0.0    1011.7   10.0  \n...          ...         ...     ...       ...    ...  \n284545       230     9.20624     0.0    1016.5   10.0  \n284546       230     9.20624     0.0    1016.5   10.0  \n284547       230     9.20624     0.0    1016.5   10.0  \n284548       230     9.20624     0.0    1016.5   10.0  \n284549       240     9.20624     0.0    1016.3   10.0  \n\n[284550 rows x 20 columns]\n数据载入完毕============================================1\n\n\n\n\n数据处理\n\nCare_data['result'] = Care_data['arr_delay'].apply(lambda x: 1 if x &gt; 0 else 0)\nprint('二分类变量添加完毕=========================================2')\n\n二分类变量添加完毕=========================================2\n\n\n\nplt.rcParams['font.sans-serif'] = ['SimHei']  # 设置默认字体为SimHei，支持中文显示\nplt.rcParams['axes.unicode_minus'] = False  # 解决保存图像时负号'-'显示为方块的问题\nsns.countplot(x='result', data=Care_data)\nplt.show()\nprint('变量分布图创建完毕=====================================3')\n\n\n\n\n\n\n\n\n变量分布图创建完毕=====================================3\n\n\n数据分布不太均衡，正常：延迟 约=5:3\n\ncategorical_features = ['month', 'day', 'hour','carrier', 'origin', 'dest']\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, categorical_features)],\n    remainder='passthrough')  # 对于非分类特征，直接传递\nprint('独热编码进行完毕=======================================4')\n\n独热编码进行完毕=======================================4\n\n\n\n\n划分训练集和测试集\n以8:2的比例划分训练集和测试集\n\nX = Care_data.drop(columns=['result', 'arr_delay'])  # 假设'result'是目标变量的新名称，'arr_delay'用于生成'result'\nY = Care_data['result']\nnp.random.seed(1234)\nTrainX, TestX, TrainY, TestY = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\nprint('训练集和测试集划分完毕==================================5')\nTrainX\n\n训练集和测试集划分完毕==================================5\n\n\n\n\n\n\n\n\n\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\nsched_arr_time\ncarrier\norigin\ndest\nair_time\ndistance\nhour\ntemp\nhumid\nwind_dir\nwind_speed\nprecip\npressure\nvisib\n\n\n\n\n58312\n11\n12\n1754\n1800\n-6\n2039\nDL\nLGA\nATL\n122\n762\n18\n35.96\n45.76\n330\n19.56326\n0.0\n1024.5\n10.0\n\n\n269753\n9\n13\n1808\n1725\n43\n2015\nUA\nEWR\nIAH\n184\n1400\n17\n73.04\n47.59\n330\n21.86482\n0.0\n1006.3\n10.0\n\n\n240867\n8\n8\n807\n815\n-8\n930\nMQ\nJFK\nDCA\n39\n213\n8\n71.96\n93.49\n160\n10.35702\n0.0\n1018.6\n10.0\n\n\n130240\n3\n21\n820\n824\n-4\n1014\nEV\nEWR\nRDU\n79\n416\n8\n32.00\n51.15\n350\n12.65858\n0.0\n1008.4\n10.0\n\n\n224635\n7\n19\n1503\n1454\n9\n1710\nEV\nLGA\nCLT\n78\n544\n14\n98.06\n40.44\n220\n13.80936\n0.0\n1010.6\n10.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n65739\n11\n21\n934\n910\n24\n1130\nEV\nLGA\nCLT\n93\n544\n9\n42.98\n55.27\n50\n10.35702\n0.0\n1036.3\n10.0\n\n\n116683\n3\n3\n949\n956\n-7\n1240\nB6\nJFK\nLAS\n319\n2248\n9\n33.08\n48.98\n330\n13.80936\n0.0\n1007.0\n10.0\n\n\n106675\n2\n18\n1202\n1204\n-2\n1426\nUA\nEWR\nDEN\n228\n1605\n12\n33.08\n27.40\n290\n20.71404\n0.0\n1023.5\n10.0\n\n\n249943\n8\n19\n1514\n1520\n-6\n1705\nAA\nLGA\nSTL\n123\n888\n15\n80.06\n48.64\n230\n11.50780\n0.0\n1017.0\n10.0\n\n\n64229\n11\n19\n1651\n1659\n-8\n2034\nB6\nJFK\nOAK\n352\n2576\n16\n44.06\n43.02\n340\n17.26170\n0.0\n1021.0\n10.0\n\n\n\n\n227640 rows × 19 columns\n\n\n\n\n\n5折交叉验证\n5折交叉验证的原理是将训练数据划分成5份，训练5次，每次用其中一份作为测试集，其余4份作为训练集。通过多次训练取平均来避免模型的过度拟合，提升模型的泛化能力。\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n\n\n在测试集表现评价函数\n构建一个综合函数来评价不同的机器学习模型在测试集上的表现。包含混淆矩阵、Kappa值、准确率、精确率、召回率、F1score 6个评价指标。\n\ndef myconfusionmatrix(TestY, y_pred):\n    # 混淆矩阵\n    cm = confusion_matrix(TestY, y_pred)\n    # Kappa值\n    kappa = cohen_kappa_score(TestY, y_pred)\n    # 计算准确率\n    accuracy = accuracy_score(TestY, y_pred)\n    # 计算精确率（对于多分类问题，需要指定平均方法，如'macro', 'micro', 'weighted'）\n    precision = precision_score(TestY, y_pred, average='macro')  # 或者使用'micro', 'weighted'等\n    # 计算召回率\n    recall = recall_score(TestY, y_pred, average='macro')  # 同样需要指定平均方法\n    # 计算F1分数\n    f1 = f1_score(TestY, y_pred, average='weighted')  # 同样需要指定平均方法\n    return (cm, accuracy, precision, recall, f1, kappa)\n\n\n\n随机森林模型构建\n由于运算量太大，此处直接展示筛选的最优参数放在调参网格中。\n\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))])\nparam_grid = {\n    'classifier__n_estimators': [300],\n    'classifier__max_features': ['sqrt'],\n    'classifier__max_depth': [10],\n    'classifier__criterion': ['gini']\n}\n\n\ngrid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\ngrid_search.fit(TrainX, TrainY)\nprint(\"Best parameters for RandomForest:\", grid_search.best_params_)\nprint(\"Best cross-validation score for RandomForest:\", grid_search.best_score_)\n\nFitting 5 folds for each of 1 candidates, totalling 5 fits\nBest parameters for RandomForest: {'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__n_estimators': 300}\nBest cross-validation score for RandomForest: 0.8011597258829731\n\n\n该模型的综合评分为0.80。\n\n\n测试集上的表现\n\nbest_rf = grid_search.best_estimator_\ny_pred = best_rf.predict(TestX)\nlist2 = myconfusionmatrix(TestY, y_pred)\nconfusion_matrix = list2[0]\naccuracy = list2[1]\nprecision = list2[2]\nrecall = list2[3]\nf1_score = list2[4]\nKappa = list2[5]\nprint('输出混淆矩阵========================================7')\nprint(f\"Confusion Matrix:\\n{confusion_matrix}\\nKappa:{Kappa}\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1_score}\")\n\n输出混淆矩阵========================================7\nConfusion Matrix:\n[[33443  1456]\n [ 9901 12110]]\nKappa:0.5472267358610515\nAccuracy: 0.8004392901071868\nPrecision: 0.8321222358792558\nRecall: 0.7542295312961043\nF1 Score: 0.7875237726785591\n\n\n混淆矩阵：正类是延迟，负类是正常。\n真正例（True Positive，TP）：这里是 12110，表示实际航班延迟，并且模型也正确预测为延迟抵达的样本数量。\n假正例（False Positive，FP）：位于矩阵右上角的值，即 1456，代表实际属于正常抵达，但模型错误地预测为延迟的样本数量。\n假负例（False Negative，FN）：在矩阵左下角，值为 9901，意味着实际属于延迟，然而模型却预测为正常抵达的样本数量。\n真负例（True Negative，TN）：位于矩阵左上角，也就是 33443，是实际为正常且模型也正确预测为正常抵达的样本数量。\n即：实际正常抵达的航班中有1516个预测错误；实际延迟抵达的航班中有9906个预测错误，在正类的预测中准确率不太高。\nKappa值 0.547，说明模型的分类结果相较于随机分类有一定程度的一致性，但还存在改进的空间。\n\n\n\n\n\n\n👉Kappa值的判定标准\n\n\n\n用于衡量分类任务中两个观察者（或模型预测与真实标签）之间一致性的统计指标。\n0.00~0.20：极低的一致性（slight），表示评估结果或模型预测与实际标签之间的一致性很差，可能存在较大的差异。\n0.21~0.40：较低的一致性（fair），表示有一定的一致性，但整体仍然偏低。\n0.41~0.60：中等的一致性（moderate），表示评估结果或模型预测与实际标签之间的一致性较为适中。\n0.61~0.80：较高的一致性（substantial），表示评估结果或模型预测与实际标签之间的一致性较高。\n0.81~1.00：高一致性（almost perfect），表示评估结果或模型预测与实际标签之间的一致性几乎完全一致。\n\n\n准确率 为 0.800，意味着模型总体上能正确分类大约 80% 的样本，但这个指标可能会在样本不平衡的情况下有一定误导性，比如正负样本数量差异很大时，准确率高不一定代表模型对少数类的分类能力强。\n精确率 为 0.832，表明当模型预测某个样本为正类时，有大约 83% 的概率是预测正确的。\n召回率 0.754，意味着在所有实际的正类样本里，模型能够正确找出来的比例约为 75%，反映了模型对正类样本的覆盖能力。\nF1 分数 为 0.787，代表模型在精确率和召回率上整体达到了一定的平衡水平，不过同样还有一定的提升空间。\n\n\nROC曲线绘制\n\nfrom sklearn.metrics import roc_curve, auc\n\n\n\n提取概率值\n\nrf_pred_prob = best_rf.predict_proba(TestX)[:, 1] \n\n\n\n计算AUC值\n\nfpr1, tpr1, thresholds1 = roc_curve(TestY, rf_pred_prob)  \nauc1 = auc(fpr1, tpr1) \n\n\n\n绘制ROC曲线\n\nplt.figure()  \nplt.plot(fpr1, tpr1, color='red', lw=2, label=f'Random Forest (AUC = {auc1:.2f})')  \nplt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')  \nplt.xlim([0.0, 1.0])  \nplt.ylim([0.0, 1.05])  \nplt.xlabel('False Positive Rate')  \nplt.ylabel('True Positive Rate')  \nplt.title('Receiver Operating Characteristic (ROC) Curves')  \nplt.legend(loc=\"lower right\")  \nplt.show()\n\n\n\n\n\n\n\n\n该模型的AUC值为0.84，模型训练各指标可以接受，但还有提升的空间。💯",
    "crumbs": [
      "nycflights13数据探索EDA",
      "机器学习模型"
    ]
  },
  {
    "objectID": "EDA/flights.html",
    "href": "EDA/flights.html",
    "title": "Flights数据集探索",
    "section": "",
    "text": "🛫本节导读\n\n\n\n在本章，首先对flights数据集进行可视化探索，之后对weather数据集进行了可视化探索，最后将两个数据集合并，对数据进行了清洗处理，方面后续建模。\n在本节，对于flights数据集进行可视化探索，发现了一些有趣的东西。😀",
    "crumbs": [
      "nycflights13数据探索EDA",
      "Flights数据集探索"
    ]
  },
  {
    "objectID": "EDA/flights.html#柱状图",
    "href": "EDA/flights.html#柱状图",
    "title": "Flights数据集探索",
    "section": "柱状图",
    "text": "柱状图\n\n&gt; flights|&gt;\n+   ggplot(aes(x=carrier,y = arr_delay))+\n+   geom_bar(stat = 'identity',fill = 'steelblue')+\n+   theme_bw() \n\n\n\n\n\n\n\n\n我们发现，AS、F9、HA、OO、YV航班几乎都准时到达，但是B6、DL、EV、UA这些航班的到达时间差距较大，很不稳定。 跟上图对照着看，我们发现小型公司的延误更少，他们一年中的航班数虽然少，但是几乎都准时到达，而航班数较多的大型航空公司遇到的情况更多，延误可能性更大，延误时间不稳定。",
    "crumbs": [
      "nycflights13数据探索EDA",
      "Flights数据集探索"
    ]
  },
  {
    "objectID": "EDA/flights.html#哑铃图",
    "href": "EDA/flights.html#哑铃图",
    "title": "Flights数据集探索",
    "section": "哑铃图",
    "text": "哑铃图\n\n&gt; library(ggalt)\n&gt; Arr &lt;- flights |&gt;\n+   na.omit() |&gt;\n+   group_by(carrier = as.factor(carrier)) |&gt;\n+   summarise(min = min(arr_delay), max=max(arr_delay))\n&gt; \n&gt; ggplot(Arr,aes(x= min, xend=max, y=carrier, group = carrier)) +\n+         geom_dumbbell(color=\"#a3c4dc\",\n+                       size=0.75,\n+                       colour_x =\"darkblue\",\n+                      colour_xend=\"red\",\n+                      size_x = 2,\n+               size_xend = 2) +\n+          labs(x=\"\",\n+          y=\"\",\n+        title=\"The span of arive delay at different carrier\")+\n+     theme_bw()+\n+     theme(plot.title = element_text(size=15),\n+           axis.text.x= element_text(size=10),\n+        axis.text.y= element_text(size=10),\n+         axis.title=element_text(size=10))\n\n\n\n\n\n\n\n\n航空公司与推迟时间的Dumbbell Chart(哑铃图)，采用的是最大延误时间与最小延误时间的差值（极差），大小反映在长度上。\n从图中可以看出，大多数航空公司都存在一定程度的到达延误情况。 YV 航空公司的延误跨度最长，该航空公司的到达延误时间变化范围很大。 9E、AA 等的延误跨度相对较短，这些航空公司的到达延误时间变化范围较小。",
    "crumbs": [
      "nycflights13数据探索EDA",
      "Flights数据集探索"
    ]
  },
  {
    "objectID": "EDA/flights.html#q1-为什么哑铃图展现的信息与柱状图不一样",
    "href": "EDA/flights.html#q1-为什么哑铃图展现的信息与柱状图不一样",
    "title": "Flights数据集探索",
    "section": "Q1 为什么哑铃图展现的信息与柱状图不一样？",
    "text": "Q1 为什么哑铃图展现的信息与柱状图不一样？\n柱状图中，对于每个carrier（航空公司），arr_delay对应的是一个特定的值（可能是平均值、总和或者其他汇总值），而不是最大值和最小值。\n这里将哑铃图的两端点定义为最大值和最小值，来看，不同航班的延误情况。两张图可以结合着看，得到更准确的信息。",
    "crumbs": [
      "nycflights13数据探索EDA",
      "Flights数据集探索"
    ]
  },
  {
    "objectID": "EDA/linearregression.html",
    "href": "EDA/linearregression.html",
    "title": "线性回归模型",
    "section": "",
    "text": "✏️本节导读\n\n\n\n本节首先对联立后的所有变量做了线性回归模型，发现可以解释89%的因变量的变异。\n但是有些变量并不显著，通过分析之后决定，删除不显著的变量。删除之后的方程所有变量均显著，且仍可以解释89%的变异。\n\n\n\n一般线性回归\n\n&gt; library(readxl)\n&gt; joined_data &lt;- read_excel(\"D:\\\\Rstudio\\\\Rmyfile\\\\Flights\\\\EDA\\\\joined_data.xlsx\")\n\n\n&gt; D &lt;- lm(arr_delay~month+day+hour+dep_time+sched_dep_time+sched_arr_time+dep_delay+carrier+origin+dest+air_time+arr_time+distance+temp+dewp+humid+wind_dir+wind_speed+pressure+visib,data = joined_data) \n&gt; summary(D)\n   \n   Call:\n   lm(formula = arr_delay ~ month + day + hour + dep_time + sched_dep_time + \n       sched_arr_time + dep_delay + carrier + origin + dest + air_time + \n       arr_time + distance + temp + dewp + humid + wind_dir + wind_speed + \n       pressure + visib, data = joined_data)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n   -55.128  -8.597  -1.601   6.368 163.697 \n   \n   Coefficients:\n                    Estimate Std. Error  t value Pr(&gt;|t|)    \n   (Intercept)     4.512e+01  1.244e+01    3.628 0.000286 ***\n   month           4.290e-02  8.121e-03    5.283 1.27e-07 ***\n   day             1.940e-02  2.974e-03    6.522 6.97e-11 ***\n   hour            1.289e+00  1.409e-01    9.146  &lt; 2e-16 ***\n   dep_time        2.741e-03  2.062e-04   13.290  &lt; 2e-16 ***\n   sched_dep_time -1.515e-02  1.432e-03  -10.583  &lt; 2e-16 ***\n   sched_arr_time -2.596e-03  1.129e-04  -23.003  &lt; 2e-16 ***\n   dep_delay       1.012e+00  7.554e-04 1340.121  &lt; 2e-16 ***\n   carrierAA       2.334e+00  1.777e-01   13.132  &lt; 2e-16 ***\n   carrierAS      -1.940e+00  6.471e-01   -2.998 0.002718 ** \n   carrierB6       6.975e+00  1.535e-01   45.445  &lt; 2e-16 ***\n   carrierDL       2.120e+00  1.583e-01   13.392  &lt; 2e-16 ***\n   carrierEV       3.318e+00  1.594e-01   20.816  &lt; 2e-16 ***\n   carrierF9       7.001e+00  6.244e-01   11.212  &lt; 2e-16 ***\n   carrierFL       6.496e+00  3.625e-01   17.921  &lt; 2e-16 ***\n   carrierHA      -6.268e+00  1.153e+00   -5.434 5.51e-08 ***\n   carrierMQ       8.738e+00  1.653e-01   52.860  &lt; 2e-16 ***\n   carrierOO       4.995e+00  2.678e+00    1.865 0.062155 .  \n   carrierUA       1.574e+00  1.753e-01    8.979  &lt; 2e-16 ***\n   carrierUS       6.974e+00  2.025e-01   34.437  &lt; 2e-16 ***\n   carrierVX      -2.748e+00  2.731e-01  -10.061  &lt; 2e-16 ***\n   carrierWN      -2.055e+00  2.470e-01   -8.321  &lt; 2e-16 ***\n   carrierYV       3.868e+00  6.570e-01    5.887 3.94e-09 ***\n   originJFK      -1.458e+00  1.229e-01  -11.862  &lt; 2e-16 ***\n   originLGA       7.831e-01  1.208e-01    6.484 8.92e-11 ***\n   destACK        -8.419e+01  1.050e+01   -8.021 1.06e-15 ***\n   destALB        -8.440e+01  1.076e+01   -7.847 4.29e-15 ***\n   destANC         1.087e+02  1.114e+01    9.759  &lt; 2e-16 ***\n   destATL        -4.775e+01  6.891e+00   -6.929 4.24e-12 ***\n   destAUS        -1.322e+01  2.194e+00   -6.027 1.67e-09 ***\n   destAVL        -5.612e+01  7.981e+00   -7.031 2.05e-12 ***\n   destBDL        -8.538e+01  1.093e+01   -7.813 5.60e-15 ***\n   destBGR        -6.943e+01  9.349e+00   -7.427 1.12e-13 ***\n   destBHM        -4.865e+01  6.283e+00   -7.744 9.69e-15 ***\n   destBNA        -5.250e+01  6.873e+00   -7.638 2.21e-14 ***\n   destBOS        -8.224e+01  1.048e+01   -7.847 4.27e-15 ***\n   destBQN         1.496e+01  1.883e+00    7.948 1.90e-15 ***\n   destBTV        -7.562e+01  1.001e+01   -7.553 4.26e-14 ***\n   destBUF        -7.758e+01  9.820e+00   -7.900 2.79e-15 ***\n   destBUR         3.542e+01  4.263e+00    8.310  &lt; 2e-16 ***\n   destBWI        -7.952e+01  1.057e+01   -7.526 5.24e-14 ***\n   destBZN         1.157e+01  2.733e+00    4.232 2.32e-05 ***\n   destCAE        -4.511e+01  7.937e+00   -5.684 1.32e-08 ***\n   destCAK        -6.805e+01  9.230e+00   -7.372 1.68e-13 ***\n   destCHO        -7.684e+01  1.001e+01   -7.677 1.64e-14 ***\n   destCHS        -5.590e+01  7.660e+00   -7.298 2.93e-13 ***\n   destCLE        -6.996e+01  9.064e+00   -7.718 1.18e-14 ***\n   destCLT        -6.383e+01  8.256e+00   -7.731 1.07e-14 ***\n   destCMH        -6.746e+01  8.680e+00   -7.772 7.76e-15 ***\n   destCRW        -7.089e+01  8.997e+00   -7.880 3.29e-15 ***\n   destCVG        -6.480e+01  8.013e+00   -8.086 6.17e-16 ***\n   destDAY        -6.333e+01  8.256e+00   -7.672 1.70e-14 ***\n   destDCA        -8.192e+01  1.036e+01   -7.909 2.61e-15 ***\n   destDEN        -8.071e+00  1.631e+00   -4.947 7.53e-07 ***\n   destDFW        -2.430e+01  2.969e+00   -8.184 2.76e-16 ***\n   destDSM        -4.011e+01  5.222e+00   -7.681 1.58e-14 ***\n   destDTW        -7.131e+01  8.531e+00   -8.358  &lt; 2e-16 ***\n   destEGE        -1.211e+01  1.491e+00   -8.120 4.67e-16 ***\n   destEYW        -1.433e+01  5.608e+00   -2.555 0.010626 *  \n   destFLL        -3.383e+01  4.910e+00   -6.891 5.57e-12 ***\n   destGRR        -5.764e+01  7.809e+00   -7.381 1.58e-13 ***\n   destGSO        -6.605e+01  8.809e+00   -7.497 6.52e-14 ***\n   destGSP        -5.799e+01  7.876e+00   -7.363 1.80e-13 ***\n   destHDN        -6.766e+00  4.148e+00   -1.631 0.102835    \n   destHNL         2.097e+02  2.020e+01   10.381  &lt; 2e-16 ***\n   destHOU        -2.088e+01  2.743e+00   -7.613 2.68e-14 ***\n   destIAD        -8.042e+01  1.028e+01   -7.826 5.04e-15 ***\n   destIAH        -1.732e+01  2.810e+00   -6.165 7.07e-10 ***\n   destILM        -6.969e+01  8.655e+00   -8.052 8.19e-16 ***\n   destIND        -5.930e+01  7.527e+00   -7.878 3.34e-15 ***\n   destJAC         1.231e+01  3.261e+00    3.774 0.000161 ***\n   destJAX        -4.626e+01  6.448e+00   -7.175 7.22e-13 ***\n   destLAS         2.750e+01  2.846e+00    9.663  &lt; 2e-16 ***\n   destLAX         4.363e+01  4.243e+00   10.283  &lt; 2e-16 ***\n   destLEX        -5.429e+01  1.596e+01   -3.402 0.000669 ***\n   destLGB         3.386e+01  4.234e+00    7.997 1.28e-15 ***\n   destMCI        -3.715e+01  4.713e+00   -7.883 3.20e-15 ***\n   destMCO        -4.042e+01  5.706e+00   -7.084 1.41e-12 ***\n   destMDW        -5.299e+01  7.116e+00   -7.446 9.64e-14 ***\n   destMEM        -4.449e+01  5.629e+00   -7.904 2.72e-15 ***\n   destMHT        -7.844e+01  1.034e+01   -7.585 3.34e-14 ***\n   destMIA        -3.269e+01  4.783e+00   -6.835 8.19e-12 ***\n   destMKE        -5.327e+01  7.031e+00   -7.576 3.57e-14 ***\n   destMSN        -5.078e+01  6.588e+00   -7.708 1.28e-14 ***\n   destMSP        -4.183e+01  5.242e+00   -7.980 1.47e-15 ***\n   destMSY        -3.113e+01  4.239e+00   -7.344 2.08e-13 ***\n   destMTJ        -9.028e+00  3.959e+00   -2.280 0.022606 *  \n   destMVY        -8.779e+01  1.067e+01   -8.224  &lt; 2e-16 ***\n   destMYR        -6.625e+01  8.371e+00   -7.914 2.49e-15 ***\n   destOAK         4.066e+01  4.961e+00    8.197 2.48e-16 ***\n   destOKC        -1.990e+01  3.364e+00   -5.915 3.33e-09 ***\n   destOMA        -3.458e+01  4.475e+00   -7.726 1.11e-14 ***\n   destORD        -6.084e+01  7.064e+00   -8.613  &lt; 2e-16 ***\n   destORF        -7.660e+01  9.865e+00   -7.764 8.24e-15 ***\n   destPBI        -3.376e+01  5.168e+00   -6.533 6.47e-11 ***\n   destPDX         3.408e+01  4.125e+00    8.263  &lt; 2e-16 ***\n   destPHL        -8.744e+01  1.113e+01   -7.860 3.87e-15 ***\n   destPHX         1.953e+01  2.290e+00    8.527  &lt; 2e-16 ***\n   destPIT        -7.657e+01  9.587e+00   -7.987 1.39e-15 ***\n   destPSE         1.635e+01  1.815e+00    9.007  &lt; 2e-16 ***\n   destPSP         3.244e+01  5.041e+00    6.436 1.23e-10 ***\n   destPVD        -7.935e+01  1.065e+01   -7.450 9.39e-14 ***\n   destPWM        -7.455e+01  9.946e+00   -7.496 6.61e-14 ***\n   destRDU        -6.931e+01  8.997e+00   -7.703 1.33e-14 ***\n   destRIC        -7.645e+01  9.882e+00   -7.737 1.02e-14 ***\n   destROC        -7.975e+01  1.006e+01   -7.928 2.24e-15 ***\n   destRSW        -3.898e+01  4.890e+00   -7.973 1.56e-15 ***\n   destSAN         3.980e+01  4.064e+00    9.794  &lt; 2e-16 ***\n   destSAT        -1.417e+01  1.898e+00   -7.469 8.08e-14 ***\n   destSAV        -5.242e+01  7.154e+00   -7.327 2.37e-13 ***\n   destSBN        -6.590e+01  9.028e+00   -7.299 2.91e-13 ***\n   destSDF        -6.121e+01  7.564e+00   -8.093 5.86e-16 ***\n   destSEA         3.111e+01  3.919e+00    7.939 2.05e-15 ***\n   destSFO         4.534e+01  4.934e+00    9.190  &lt; 2e-16 ***\n   destSJC         4.110e+01  4.912e+00    8.366  &lt; 2e-16 ***\n   destSJU         1.305e+01  1.720e+00    7.588 3.25e-14 ***\n   destSLC         9.879e+00  1.428e+00    6.916 4.65e-12 ***\n   destSMF         4.284e+01  4.627e+00    9.259  &lt; 2e-16 ***\n   destSNA         3.039e+01  4.110e+00    7.393 1.44e-13 ***\n   destSRQ        -3.842e+01  5.112e+00   -7.515 5.69e-14 ***\n   destSTL        -4.734e+01  6.093e+00   -7.771 7.83e-15 ***\n   destSTT         1.459e+01  1.689e+00    8.639  &lt; 2e-16 ***\n   destSYR        -8.285e+01  1.041e+01   -7.957 1.77e-15 ***\n   destTPA        -3.755e+01  5.327e+00   -7.050 1.80e-12 ***\n   destTUL        -2.756e+01  4.031e+00   -6.837 8.08e-12 ***\n   destTVC        -6.199e+01  7.704e+00   -8.046 8.55e-16 ***\n   destTYS        -5.478e+01  7.648e+00   -7.163 7.92e-13 ***\n   destXNA        -3.590e+01  4.482e+00   -8.009 1.16e-15 ***\n   air_time        9.085e-01  2.433e-03  373.345  &lt; 2e-16 ***\n   arr_time        1.230e-03  8.661e-05   14.201  &lt; 2e-16 ***\n   distance       -1.704e-01  6.415e-03  -26.570  &lt; 2e-16 ***\n   temp            1.724e-01  1.609e-02   10.713  &lt; 2e-16 ***\n   dewp            2.275e-02  1.734e-02    1.312 0.189583    \n   humid           3.250e-02  8.892e-03    3.655 0.000258 ***\n   wind_dir       -6.123e-03  2.904e-04  -21.087  &lt; 2e-16 ***\n   wind_speed      2.087e-01  5.539e-03   37.677  &lt; 2e-16 ***\n   pressure        1.509e-02  4.089e-03    3.691 0.000223 ***\n   visib          -4.565e-01  2.271e-02  -20.103  &lt; 2e-16 ***\n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 13.87 on 284412 degrees of freedom\n   Multiple R-squared:  0.891,  Adjusted R-squared:  0.8909 \n   F-statistic: 1.697e+04 on 137 and 284412 DF,  p-value: &lt; 2.2e-16\n\n将几乎所有的变量都放进去之后，发现拟合效果较好，可以解释89%的延迟到达的变异，但是有几个变量不显著，现对这些变量进行分析。\n上面提到的两个正相关的变量temp与dewp的P值中 temp十分显著，dewp的P=0.23&gt;0.05。根据前一章我们对于这两个变量之间关系的探索，发现二者呈现高度的正相关。因此我们分别对两个变量做一个单变量的线性回归做一下验证。\n\n&gt; lm(data = joined_data,arr_delay~temp) |&gt;summary()\n   \n   Call:\n   lm(formula = arr_delay ~ temp, data = joined_data)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n    -91.50  -22.14  -10.27    7.14 1268.50 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept) -1.20669    0.25970  -4.647 3.38e-06 ***\n   temp         0.10475    0.00435  24.080  &lt; 2e-16 ***\n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 41.94 on 284548 degrees of freedom\n   Multiple R-squared:  0.002034,   Adjusted R-squared:  0.00203 \n   F-statistic: 579.8 on 1 and 284548 DF,  p-value: &lt; 2.2e-16\n&gt; lm(data = joined_data,arr_delay~dewp) |&gt;summary()\n   \n   Call:\n   lm(formula = arr_delay ~ dewp, data = joined_data)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n    -93.52  -22.19  -10.06    7.44 1267.78 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept) -1.89496    0.18056  -10.49   &lt;2e-16 ***\n   dewp         0.16515    0.00404   40.88   &lt;2e-16 ***\n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 41.86 on 284548 degrees of freedom\n   Multiple R-squared:  0.005839,   Adjusted R-squared:  0.005836 \n   F-statistic:  1671 on 1 and 284548 DF,  p-value: &lt; 2.2e-16\n\n我们发现,两个模型均显著，但我们上面全模型中，dewp并不显著。因此我们认为，在对arr_delay的贡献上，dewp可能会抢temp的功劳而认为其与航班推迟有关，而其实是因为dewp与temp有关所以才在单个模型中显著。当二者同时出现在模型中时，真正起作用的变量就体现出来了。证实了我们课上的结论。因此之后筛选模型时，将会优先考虑使用temp而不是dewp。故删去在全模型中不显著的dewp。\n\n\n观察变量之间的相关性\n将关心的变量中数值类型和字符类型分开处理\n\n&gt; numdata &lt;- joined_data[,c(4:9,15:17,20:27)]\n&gt; strdata &lt;- joined_data[,c(2,3,10,13,14)]\n\n对于数值类型变量做相关性图\n\n&gt; library(corrplot)\n&gt; corrplot(corr = cor(numdata),type = 'upper')\n\n\n\n\n\n\n\n\n发现，arr_delay与dep_delay之间有很强的相关性，因此在回归方程中引入dep_delay变量。解释为：离开延迟，大概率到达也会延迟。\n\n\n\n\n\n\nQ5 dep_delay与dep_time和sched_dep_time是存在线性关系的,为什么模型中二者的解释程度却有很大差别？\n\n\n\ndep_delay=dep_time-sched_dep_time。但是为什么在模型中arr_delay出现（89%）与dep_time和sched_dep_time同时出现（20%）的效果差别很大？\n下面进行讨论：\n\n\n\n&gt; lm(dep_delay~dep_time+sched_dep_time,data = joined_data) |&gt;summary()\n   \n   Call:\n   lm(formula = dep_delay ~ dep_time + sched_dep_time, data = joined_data)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n    -59.84  -15.79   -8.02   -0.23 1314.74 \n   \n   Coefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)    -1.001e+01  2.040e-01  -49.06   &lt;2e-16 ***\n   dep_time        6.751e-02  4.854e-04  139.09   &lt;2e-16 ***\n   sched_dep_time -5.223e-02  5.050e-04 -103.42   &lt;2e-16 ***\n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 35.72 on 284547 degrees of freedom\n   Multiple R-squared:  0.09704,    Adjusted R-squared:  0.09704 \n   F-statistic: 1.529e+04 on 2 and 284547 DF,  p-value: &lt; 2.2e-16\n\n简单的线性方程并不能识别数据中的这种直接的关系，至于具体的原因我还没有找到答案~\n但可以知道的是dep_delay与dep_time和sched_dep_time一起的作用并不相同，二者的纯线性关系在数据拟合的过程中并不能别识别，鉴于三个变量在方程中均显著，因此三个变量同时存在，不做删减。\n还有一个变量arr_time在方程中并不显著，故删除。\n\n\n最终回归方程\n因为结果太长，故此处结果略，回归方程拟合优度(adjust R2)为89.09%。\n\n&gt; library(easystats)\n&gt; model_final &lt;- D|&gt;\n+   select_parameters() \n&gt; summary(model_final)\n   \n   Call:\n   lm(formula = arr_delay ~ month + day + hour + dep_time + sched_dep_time + \n       sched_arr_time + dep_delay + carrier + origin + dest + air_time + \n       distance + temp + humid + wind_dir + wind_speed + pressure + \n       visib + precip, data = joined_data)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n   -54.960  -8.597  -1.603   6.377 164.266 \n   \n   Coefficients:\n                    Estimate Std. Error  t value Pr(&gt;|t|)    \n   (Intercept)     4.326e+01  1.240e+01    3.490 0.000483 ***\n   month           4.037e-02  8.115e-03    4.975 6.54e-07 ***\n   day             1.862e-02  2.974e-03    6.261 3.84e-10 ***\n   hour            1.311e+00  1.409e-01    9.304  &lt; 2e-16 ***\n   dep_time        3.138e-03  2.045e-04   15.341  &lt; 2e-16 ***\n   sched_dep_time -1.559e-02  1.432e-03  -10.893  &lt; 2e-16 ***\n   sched_arr_time -1.700e-03  9.345e-05  -18.194  &lt; 2e-16 ***\n   dep_delay       1.010e+00  7.421e-04 1361.099  &lt; 2e-16 ***\n   carrierAA       2.326e+00  1.777e-01   13.087  &lt; 2e-16 ***\n   carrierAS      -1.975e+00  6.471e-01   -3.053 0.002269 ** \n   carrierB6       6.899e+00  1.534e-01   44.977  &lt; 2e-16 ***\n   carrierDL       2.119e+00  1.583e-01   13.385  &lt; 2e-16 ***\n   carrierEV       3.294e+00  1.594e-01   20.662  &lt; 2e-16 ***\n   carrierF9       7.107e+00  6.244e-01   11.382  &lt; 2e-16 ***\n   carrierFL       6.527e+00  3.625e-01   18.008  &lt; 2e-16 ***\n   carrierHA      -6.328e+00  1.153e+00   -5.486 4.10e-08 ***\n   carrierMQ       8.721e+00  1.653e-01   52.758  &lt; 2e-16 ***\n   carrierOO       5.086e+00  2.678e+00    1.899 0.057546 .  \n   carrierUA       1.553e+00  1.753e-01    8.856  &lt; 2e-16 ***\n   carrierUS       6.933e+00  2.025e-01   34.239  &lt; 2e-16 ***\n   carrierVX      -2.783e+00  2.731e-01  -10.189  &lt; 2e-16 ***\n   carrierWN      -2.039e+00  2.470e-01   -8.258  &lt; 2e-16 ***\n   carrierYV       3.907e+00  6.570e-01    5.947 2.73e-09 ***\n   originJFK      -1.423e+00  1.229e-01  -11.578  &lt; 2e-16 ***\n   originLGA       7.985e-01  1.207e-01    6.616 3.70e-11 ***\n   destACK        -8.629e+01  1.050e+01   -8.221  &lt; 2e-16 ***\n   destALB        -8.646e+01  1.075e+01   -8.039 9.08e-16 ***\n   destANC         1.111e+02  1.114e+01    9.970  &lt; 2e-16 ***\n   destATL        -4.909e+01  6.890e+00   -7.124 1.05e-12 ***\n   destAUS        -1.370e+01  2.193e+00   -6.246 4.22e-10 ***\n   destAVL        -5.767e+01  7.981e+00   -7.226 4.98e-13 ***\n   destBDL        -8.754e+01  1.093e+01   -8.012 1.13e-15 ***\n   destBGR        -7.130e+01  9.348e+00   -7.628 2.40e-14 ***\n   destBHM        -4.979e+01  6.282e+00   -7.925 2.29e-15 ***\n   destBNA        -5.384e+01  6.873e+00   -7.834 4.74e-15 ***\n   destBOS        -8.435e+01  1.048e+01   -8.049 8.36e-16 ***\n   destBQN         1.455e+01  1.882e+00    7.732 1.06e-14 ***\n   destBTV        -7.767e+01  1.001e+01   -7.760 8.54e-15 ***\n   destBUF        -7.953e+01  9.819e+00   -8.099 5.54e-16 ***\n   destBUR         3.651e+01  4.262e+00    8.566  &lt; 2e-16 ***\n   destBWI        -8.164e+01  1.056e+01   -7.727 1.10e-14 ***\n   destBZN         1.180e+01  2.733e+00    4.316 1.59e-05 ***\n   destCAE        -4.642e+01  7.936e+00   -5.849 4.95e-09 ***\n   destCAK        -6.993e+01  9.229e+00   -7.577 3.56e-14 ***\n   destCHO        -7.881e+01  1.001e+01   -7.875 3.42e-15 ***\n   destCHS        -5.737e+01  7.659e+00   -7.491 6.86e-14 ***\n   destCLE        -7.175e+01  9.063e+00   -7.916 2.46e-15 ***\n   destCLT        -6.545e+01  8.255e+00   -7.929 2.22e-15 ***\n   destCMH        -6.916e+01  8.679e+00   -7.969 1.61e-15 ***\n   destCRW        -7.255e+01  8.996e+00   -8.065 7.36e-16 ***\n   destCVG        -6.640e+01  8.012e+00   -8.287  &lt; 2e-16 ***\n   destDAY        -6.498e+01  8.255e+00   -7.872 3.51e-15 ***\n   destDCA        -8.399e+01  1.036e+01   -8.110 5.08e-16 ***\n   destDEN        -8.304e+00  1.631e+00   -5.091 3.56e-07 ***\n   destDFW        -2.481e+01  2.969e+00   -8.358  &lt; 2e-16 ***\n   destDSM        -4.105e+01  5.222e+00   -7.860 3.85e-15 ***\n   destDTW        -7.300e+01  8.531e+00   -8.557  &lt; 2e-16 ***\n   destEGE        -1.207e+01  1.491e+00   -8.095 5.76e-16 ***\n   destEYW        -1.506e+01  5.608e+00   -2.685 0.007255 ** \n   destFLL        -3.474e+01  4.910e+00   -7.075 1.50e-12 ***\n   destGRR        -5.913e+01  7.808e+00   -7.573 3.67e-14 ***\n   destGSO        -6.775e+01  8.808e+00   -7.692 1.46e-14 ***\n   destGSP        -5.955e+01  7.875e+00   -7.562 3.98e-14 ***\n   destHDN        -6.739e+00  4.148e+00   -1.625 0.104218    \n   destHNL         2.141e+02  2.020e+01   10.601  &lt; 2e-16 ***\n   destHOU        -2.136e+01  2.743e+00   -7.789 6.76e-15 ***\n   destIAD        -8.245e+01  1.027e+01   -8.024 1.02e-15 ***\n   destIAH        -1.781e+01  2.810e+00   -6.340 2.30e-10 ***\n   destILM        -7.156e+01  8.654e+00   -8.269  &lt; 2e-16 ***\n   destIND        -6.078e+01  7.527e+00   -8.075 6.79e-16 ***\n   destJAC         1.257e+01  3.261e+00    3.853 0.000117 ***\n   destJAX        -4.764e+01  6.447e+00   -7.389 1.48e-13 ***\n   destLAS         2.816e+01  2.845e+00    9.897  &lt; 2e-16 ***\n   destLAX         4.455e+01  4.242e+00   10.500  &lt; 2e-16 ***\n   destLEX        -5.574e+01  1.596e+01   -3.493 0.000477 ***\n   destLGB         3.488e+01  4.233e+00    8.240  &lt; 2e-16 ***\n   destMCI        -3.803e+01  4.713e+00   -8.069 7.13e-16 ***\n   destMCO        -4.152e+01  5.706e+00   -7.278 3.41e-13 ***\n   destMDW        -5.442e+01  7.115e+00   -7.649 2.03e-14 ***\n   destMEM        -4.554e+01  5.629e+00   -8.091 5.94e-16 ***\n   destMHT        -8.052e+01  1.034e+01   -7.787 6.90e-15 ***\n   destMIA        -3.359e+01  4.783e+00   -7.023 2.18e-12 ***\n   destMKE        -5.465e+01  7.030e+00   -7.774 7.63e-15 ***\n   destMSN        -5.200e+01  6.588e+00   -7.893 2.95e-15 ***\n   destMSP        -4.283e+01  5.242e+00   -8.171 3.06e-16 ***\n   destMSY        -3.194e+01  4.238e+00   -7.537 4.81e-14 ***\n   destMTJ        -8.932e+00  3.959e+00   -2.256 0.024079 *  \n   destMVY        -8.994e+01  1.067e+01   -8.427  &lt; 2e-16 ***\n   destMYR        -6.780e+01  8.371e+00   -8.100 5.51e-16 ***\n   destOAK         4.181e+01  4.960e+00    8.429  &lt; 2e-16 ***\n   destOKC        -2.061e+01  3.364e+00   -6.127 8.97e-10 ***\n   destOMA        -3.551e+01  4.475e+00   -7.935 2.11e-15 ***\n   destORD        -6.223e+01  7.063e+00   -8.810  &lt; 2e-16 ***\n   destORF        -7.855e+01  9.864e+00   -7.963 1.68e-15 ***\n   destPBI        -3.470e+01  5.168e+00   -6.714 1.89e-11 ***\n   destPDX         3.477e+01  4.125e+00    8.431  &lt; 2e-16 ***\n   destPHL        -8.967e+01  1.112e+01   -8.061 7.59e-16 ***\n   destPHX         2.006e+01  2.290e+00    8.758  &lt; 2e-16 ***\n   destPIT        -7.847e+01  9.586e+00   -8.186 2.72e-16 ***\n   destPSE         1.603e+01  1.815e+00    8.832  &lt; 2e-16 ***\n   destPSP         3.328e+01  5.040e+00    6.602 4.05e-11 ***\n   destPVD        -8.146e+01  1.065e+01   -7.649 2.04e-14 ***\n   destPWM        -7.653e+01  9.945e+00   -7.695 1.42e-14 ***\n   destRDU        -7.108e+01  8.996e+00   -7.901 2.78e-15 ***\n   destRIC        -7.839e+01  9.881e+00   -7.934 2.13e-15 ***\n   destROC        -8.163e+01  1.006e+01   -8.115 4.87e-16 ***\n   destRSW        -3.988e+01  4.889e+00   -8.157 3.45e-16 ***\n   destSAN         4.078e+01  4.063e+00   10.036  &lt; 2e-16 ***\n   destSAT        -1.443e+01  1.897e+00   -7.605 2.87e-14 ***\n   destSAV        -5.374e+01  7.154e+00   -7.513 5.81e-14 ***\n   destSBN        -6.721e+01  9.028e+00   -7.445 9.76e-14 ***\n   destSDF        -6.289e+01  7.563e+00   -8.315  &lt; 2e-16 ***\n   destSEA         3.201e+01  3.918e+00    8.169 3.12e-16 ***\n   destSFO         4.643e+01  4.933e+00    9.412  &lt; 2e-16 ***\n   destSJC         4.226e+01  4.912e+00    8.603  &lt; 2e-16 ***\n   destSJU         1.283e+01  1.720e+00    7.460 8.70e-14 ***\n   destSLC         1.018e+01  1.428e+00    7.129 1.01e-12 ***\n   destSMF         4.386e+01  4.627e+00    9.479  &lt; 2e-16 ***\n   destSNA         3.134e+01  4.110e+00    7.626 2.43e-14 ***\n   destSRQ        -3.933e+01  5.112e+00   -7.693 1.44e-14 ***\n   destSTL        -4.853e+01  6.092e+00   -7.966 1.64e-15 ***\n   destSTT         1.449e+01  1.689e+00    8.582  &lt; 2e-16 ***\n   destSYR        -8.514e+01  1.041e+01   -8.177 2.91e-16 ***\n   destTPA        -3.857e+01  5.326e+00   -7.241 4.45e-13 ***\n   destTUL        -2.850e+01  4.031e+00   -7.070 1.55e-12 ***\n   destTVC        -6.346e+01  7.703e+00   -8.238  &lt; 2e-16 ***\n   destTYS        -5.627e+01  7.648e+00   -7.358 1.87e-13 ***\n   destXNA        -3.673e+01  4.482e+00   -8.194 2.53e-16 ***\n   air_time        9.099e-01  2.431e-03  374.250  &lt; 2e-16 ***\n   distance       -1.720e-01  6.414e-03  -26.809  &lt; 2e-16 ***\n   temp            1.949e-01  1.753e-03  111.179  &lt; 2e-16 ***\n   humid           4.126e-02  1.883e-03   21.906  &lt; 2e-16 ***\n   wind_dir       -6.069e-03  2.903e-04  -20.902  &lt; 2e-16 ***\n   wind_speed      2.068e-01  5.542e-03   37.313  &lt; 2e-16 ***\n   pressure        1.772e-02  4.088e-03    4.335 1.46e-05 ***\n   visib          -3.599e-01  2.160e-02  -16.659  &lt; 2e-16 ***\n   precip          3.098e+01  2.199e+00   14.088  &lt; 2e-16 ***\n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 13.87 on 284413 degrees of freedom\n   Multiple R-squared:  0.891,  Adjusted R-squared:  0.8909 \n   F-statistic: 1.709e+04 on 136 and 284413 DF,  p-value: &lt; 2.2e-16\n\n使用最小二乘法对方程进行筛选，删除了arr_time这个变量，因此终的变量一共纳入19个因变量，一个自变量(arr_delay)。\n\n&gt; library(writexl)\n&gt; write_xlsx(joined_data[,c(2:6,8:10,13:17,20,22:27)], \"select_data.xlsx\")",
    "crumbs": [
      "nycflights13数据探索EDA",
      "线性回归模型"
    ]
  },
  {
    "objectID": "EDA/weather.html",
    "href": "EDA/weather.html",
    "title": "Weather数据集探索",
    "section": "",
    "text": "🚴本节导读\n\n\n\n在本节对于weather数据集中各变量进行了可视化的探索，帮助我们了解数据结构，发现变量之间的关系，帮助后续探索。",
    "crumbs": [
      "nycflights13数据探索EDA",
      "Weather数据集探索"
    ]
  },
  {
    "objectID": "EDA/weather.html#q2-temp与dewp线性关系的验证",
    "href": "EDA/weather.html#q2-temp与dewp线性关系的验证",
    "title": "Weather数据集探索",
    "section": "Q2 temp与dewp线性关系的验证",
    "text": "Q2 temp与dewp线性关系的验证\n\n&gt; lm(data = weather,dewp~temp) |&gt;\n+   summary()\n   \n   Call:\n   lm(formula = dewp ~ temp, data = weather)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n   -38.805  -5.788   0.905   7.265  14.293 \n   \n   Coefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept) -12.423754   0.175153  -70.93   &lt;2e-16 ***\n   temp          0.974726   0.003017  323.06   &lt;2e-16 ***\n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 8.673 on 26112 degrees of freedom\n     (1 observation deleted due to missingness)\n   Multiple R-squared:  0.7999, Adjusted R-squared:  0.7999 \n   F-statistic: 1.044e+05 on 1 and 26112 DF,  p-value: &lt; 2.2e-16\n\n使用线性回归进行验证，发现，temp可解释dewp80%的方差，且方程显著，证实了上述发现。目前，我们并不具备相关的物理知识，但统计学角度证实了在本数据中二者具有强相关关系。\n\n\n\n\n\n\n知识补充\n\n\n\n二者在一定的情况下确实具有正相关的关系。\n从物理本质来讲，当空气中水汽含量相对稳定时，温度与露点温度呈现正相关。\n\n简单理解，在水汽含量一定的情况下，温度升高，饱和水汽压升高。而露点温度实际上是和饱和水汽压密切相关的，当空气中水汽压达到饱和水汽压时就会出现凝结，这个对应的温度就是露点温度。所以当温度升高，饱和水汽压升高，对应的露点温度也会升高，这就解释了在水汽含量稳定的情况下，二者的正相关性。\n气象环境角度\n\n在实际气象环境中，在一定的区域和时段内，空气团的水汽来源相对稳定。例如，在海洋性气候区域，空气团长期受海洋水汽的影响，水汽含量相对稳定。如果对这个区域的气象数据进行回归分析，由于水汽输入相对固定，温度的上升或者下降会伴随着露点温度的同方向变化。",
    "crumbs": [
      "nycflights13数据探索EDA",
      "Weather数据集探索"
    ]
  },
  {
    "objectID": "TCM/contents2.html",
    "href": "TCM/contents2.html",
    "title": "天然血管保护剂的理论预测",
    "section": "",
    "text": "思路简介\n\n\n\n—该数据有196条数据，主要是由6种蛋白化合物构成，例如：黄酮类、皂苷类、生物碱类、酚类、萜类、苯丙素类。\n—本研究的主要目的是构建模型，使用蛋白化合物与十三个靶点蛋白的结合能预测log10ec50值，进而判断该蛋白化合物舒张血管的作用的强弱，进而自动帮助我们筛选具有舒张血管作用的蛋白化合物，一定程度上减少一个一个做实验验证带来的人力、物力、财力和时间的花费。\n—首先我们尝试了使用直接使用连续型的数据ec50做预测，由于数据不满足正态性，于是考虑log10ec50作为因变量。\n—第一步我们考虑使用线性回归模型对数据进行拟合，效果不太理想，考虑到非线性关系以及不同种类化合物之间数据差异原因。\n—第二步考虑使用连续型的机器学习模型预测log10ec50值，并加入种类变量，期望机器学习模型发现其中的非线性关系，但效果欠佳。\n—第三步考虑将因变量根据ec50大于或小于300划分为二分类的变量，预测结果为是否具有舒张血管的作用，最终选取随机森林模型，准确率为0.875，AUC值为0.891。\n\n\n\n\n\n\n\n\n✍️目录\n\n\n\n\n线性回归模型\n连续型机器学习模型\n二分类机器学习模型\n\n✈️ Let’s go on!",
    "crumbs": [
      "中医药研究TCM",
      "天然血管保护剂的理论预测"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html",
    "href": "TCM/线性回归模型.html",
    "title": "线性回归模型",
    "section": "",
    "text": "✏️本节导读\n\n\n\n本节首先对自变量进行标准化，由于因变量不满足正态分布，于是将其取对数变为log10ec50；\n之后观察各自变量与因变量之间是否存在线性关系，构建十三个自变量与自变量之间的多元回归模型；\n对回归模型进行诊断，发现存在多重共线性，拟合程度低等问题；进一步分析发现根本原因是不同种类的数据之间差异太大； 于是分种类构建多元线性回归模型，并通过最优子集法筛选简化变量，拟合度较高。",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#以ec50为因变量",
    "href": "TCM/线性回归模型.html#以ec50为因变量",
    "title": "线性回归模型",
    "section": "以ec50为因变量",
    "text": "以ec50为因变量\n以ec50为因变量作图，我们发现，由于ec50值跨度太大，无法体现其与各个自变量之间是否具有线性趋势。因此我们尝试log10ec50作为我们的因变量。\n\n&gt; A &lt;- names(EC50)[1:2]\n&gt; for(i in A){\n+ a &lt;- ggplot(data= EC50,mapping= aes_string(x=i,y=\"ec50\",group=1))+\n+   geom_point()+\n+   geom_smooth(method = \"lm\")\n+ print(a)\n+ }",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#以log10ec50为因变量",
    "href": "TCM/线性回归模型.html#以log10ec50为因变量",
    "title": "线性回归模型",
    "section": "以log10ec50为因变量",
    "text": "以log10ec50为因变量\n\n&gt; for(i in A){\n+ a &lt;- ggplot(data= EC50,mapping= aes_string(x=i,y=\"log10ec50\",group=1))+\n+   geom_point()+\n+   geom_smooth(method = \"lm\")\n+ print(a)\n+ }",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#各种化合物类型的结合能差异",
    "href": "TCM/线性回归模型.html#各种化合物类型的结合能差异",
    "title": "线性回归模型",
    "section": "各种化合物类型的结合能差异",
    "text": "各种化合物类型的结合能差异\n\n&gt; library(readxl)\n&gt; EC50_1 &lt;- read_excel(\"D:\\\\Rstudio\\\\Rmyfile\\\\Traditional Chinese Medicine\\\\EC50种类图.xlsx\")\n&gt; EC50_1$ec50 &lt;- as.numeric(EC50_1$ec50)\n&gt; EC50_1$log10ec50 &lt;- log10(EC50_1$ec50)\n\n\n&gt; library(tidyverse)\n&gt; p1 &lt;-ggplot(data = EC50_1 ,aes(x=Species,y=log10ec50))+\n+   geom_boxplot()+\n+   theme_classic()\n&gt; p2 &lt;-ggplot(data = EC50_1 ,aes(x=Species,y=AKT1))+\n+   geom_boxplot()+\n+   theme_classic()\n&gt; p3 &lt;-ggplot(data = EC50_1 ,aes(x=Species,y=PKC))+\n+   geom_boxplot()+\n+   theme_classic()\n\n\n&gt; library(gridExtra)\n&gt; library(dplyr)\n&gt; p_final &lt;- grid.arrange(p1, arrangeGrob(p2, p3, ncol=2), nrow=2, heights=c(1, 1.5))\n\n\n\n\n\n\n\n&gt; ggsave(\"EC50种类分布图.png\",p_final,width = 12, height = 6, dpi = 300)\n\n\n\n\n\n\n\nNote\n\n\n\n我们发现不同种类的log10ec50值存在差异。\n不同种类蛋白化合物与靶点蛋白的结合能也存在差异。\n这将导致数据整体之间的方差增大。使得线性模型集合比较困难。",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#线性模型诊断",
    "href": "TCM/线性回归模型.html#线性模型诊断",
    "title": "线性回归模型",
    "section": "线性模型诊断",
    "text": "线性模型诊断\n对已经构建的模型进行诊断：\n满足正态性，方差齐性，数据表现良好，但多个变量之间的共线性较高。\n\n&gt; library(YangPac)\n&gt; ModelDiagnose(model)\n\n   [1] \"------------------正态性检验--------------------\"\n   Warning: Non-normality of residuals detected (p = 0.013).\n   \n   [1] \"-----------异方差性（方差齐性）检验---------------\"\n   OK: Error variance appears to be homoscedastic (p = 0.139).\n   \n   [1] \"----------------自相关性检验--------------------\"\n   OK: Residuals appear to be independent and not autocorrelated (p = 0.510).\n   \n   [1] \"-----------多重共线性性检验---------------\"\n   # Check for Multicollinearity\n   \n   Low Correlation\n   \n      Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n      AKT1 2.62 [2.16,  3.26]         1.62      0.38     [0.31, 0.46]\n     PRKG1 3.72 [3.01,  4.69]         1.93      0.27     [0.21, 0.33]\n    CYP1A1 2.46 [2.04,  3.06]         1.57      0.41     [0.33, 0.49]\n   \n   Moderate Correlation\n   \n      Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n       PKC 6.21 [4.94,  7.91]         2.49      0.16     [0.13, 0.20]\n    PIK3CA 5.42 [4.32,  6.88]         2.33      0.18     [0.15, 0.23]\n      PDE5 8.94 [7.05, 11.43]         2.99      0.11     [0.09, 0.14]\n      eNOS 5.86 [4.66,  7.45]         2.42      0.17     [0.13, 0.21]\n     SIRT1 8.87 [6.99, 11.34]         2.98      0.11     [0.09, 0.14]\n      PDK1 6.01 [4.78,  7.65]         2.45      0.17     [0.13, 0.21]\n     APLNR 9.09 [7.16, 11.63]         3.02      0.11     [0.09, 0.14]\n      TGR5 6.64 [5.26,  8.46]         2.58      0.15     [0.12, 0.19]\n     EDNRB 7.54 [5.96,  9.62]         2.75      0.13     [0.10, 0.17]\n   \n   High Correlation\n   \n    Term   VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    AMPK 11.39 [8.94, 14.60]         3.37      0.09     [0.07, 0.11]",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#相关性图",
    "href": "TCM/线性回归模型.html#相关性图",
    "title": "线性回归模型",
    "section": "相关性图",
    "text": "相关性图\n发现除了CYP1A1之外，其他变量之间都存在较强的正相关关系。",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#最优子集法筛选模型",
    "href": "TCM/线性回归模型.html#最优子集法筛选模型",
    "title": "线性回归模型",
    "section": "最优子集法筛选模型",
    "text": "最优子集法筛选模型\n保留了几个变量，线性关系较为显著（P&lt;0.0001)，但解释程度仍然不高(Adjusted R-squared:0.1386)。\n  \n\n\n   \n   Call:\n   lm(formula = log10ec50 ~ PDE5, data = EC50)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n   -3.6312 -0.5899  0.0133  0.7747  2.9220 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)  1.46962    0.08341  17.619  &lt; 2e-16 ***\n   PDE5        -0.47572    0.08362  -5.689 4.66e-08 ***\n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 1.168 on 194 degrees of freedom\n   Multiple R-squared:  0.143,  Adjusted R-squared:  0.1386 \n   F-statistic: 32.36 on 1 and 194 DF,  p-value: 4.657e-08",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#计算岭系数",
    "href": "TCM/线性回归模型.html#计算岭系数",
    "title": "线性回归模型",
    "section": "计算岭系数",
    "text": "计算岭系数\n\n方法1 交叉验证\n\n&gt; cvfit &lt;- cv.glmnet(x,y,type=\"mse\",nfolds = 5,alpha=0.01, missing_value = T)#交叉验证函数\n&gt; #a=0,岭回归，a=0-1之间，弹性网络，a=1,lasso回归\n&gt; plot(cvfit)\n\n\n\n\n\n\n\n&gt; cvfit$lambda.min#均方误差最小的𝜆值\n\n   [1] 1.828531\n\n\n\n\n方法2 100次迭代\n选取最小的lambda值，0.05。作为之后岭回归的惩罚系数。\n\n&gt; ridge &lt;- glmnet(x,y,family = \"gaussian\",alpha = 0)#gaussian,指的是因变量是连续性变量的情况；family=binomial因变量为分类变量\n&gt; print(ridge)\n\n   \n   Call:  glmnet(x = x, y = y, family = \"gaussian\", alpha = 0) \n   \n       Df  %Dev Lambda\n   1   13  0.00 474.50\n   2   13  0.74 432.40\n   3   13  0.81 393.90\n   4   13  0.89 358.90\n   5   13  0.97 327.10\n   6   13  1.06 298.00\n   7   13  1.16 271.50\n   8   13  1.26 247.40\n   9   13  1.38 225.40\n   10  13  1.50 205.40\n   11  13  1.63 187.20\n   12  13  1.78 170.50\n   13  13  1.93 155.40\n   14  13  2.10 141.60\n   15  13  2.28 129.00\n   16  13  2.47 117.50\n   17  13  2.68 107.10\n   18  13  2.90  97.58\n   19  13  3.13  88.91\n   20  13  3.38  81.02\n   21  13  3.64  73.82\n   22  13  3.92  67.26\n   23  13  4.21  61.29\n   24  13  4.52  55.84\n   25  13  4.84  50.88\n   26  13  5.18  46.36\n   27  13  5.52  42.24\n   28  13  5.88  38.49\n   29  13  6.25  35.07\n   30  13  6.62  31.95\n   31  13  7.01  29.12\n   32  13  7.40  26.53\n   33  13  7.79  24.17\n   34  13  8.18  22.02\n   35  13  8.58  20.07\n   36  13  8.97  18.29\n   37  13  9.35  16.66\n   38  13  9.73  15.18\n   39  13 10.09  13.83\n   40  13 10.45  12.60\n   41  13 10.79  11.48\n   42  13 11.12  10.46\n   43  13 11.44   9.53\n   44  13 11.73   8.69\n   45  13 12.02   7.92\n   46  13 12.28   7.21\n   47  13 12.53   6.57\n   48  13 12.77   5.99\n   49  13 12.98   5.46\n   50  13 13.19   4.97\n   51  13 13.38   4.53\n   52  13 13.56   4.13\n   53  13 13.72   3.76\n   54  13 13.88   3.43\n   55  13 14.02   3.12\n   56  13 14.16   2.85\n   57  13 14.29   2.59\n   58  13 14.42   2.36\n   59  13 14.54   2.15\n   60  13 14.65   1.96\n   61  13 14.76   1.79\n   62  13 14.87   1.63\n   63  13 14.98   1.48\n   64  13 15.09   1.35\n   65  13 15.20   1.23\n   66  13 15.30   1.12\n   67  13 15.41   1.02\n   68  13 15.51   0.93\n   69  13 15.62   0.85\n   70  13 15.73   0.77\n   71  13 15.84   0.70\n   72  13 15.94   0.64\n   73  13 16.05   0.58\n   74  13 16.16   0.53\n   75  13 16.27   0.49\n   76  13 16.38   0.44\n   77  13 16.50   0.40\n   78  13 16.61   0.37\n   79  13 16.71   0.33\n   80  13 16.82   0.30\n   81  13 16.93   0.28\n   82  13 17.03   0.25\n   83  13 17.13   0.23\n   84  13 17.23   0.21\n   85  13 17.33   0.19\n   86  13 17.42   0.17\n   87  13 17.51   0.16\n   88  13 17.59   0.14\n   89  13 17.67   0.13\n   90  13 17.74   0.12\n   91  13 17.81   0.11\n   92  13 17.87   0.10\n   93  13 17.93   0.09\n   94  13 17.99   0.08\n   95  13 18.04   0.08\n   96  13 18.08   0.07\n   97  13 18.12   0.06\n   98  13 18.16   0.06\n   99  13 18.19   0.05\n   100 13 18.22   0.05\n\n&gt; #100次迭代中找到最优的𝜆值；第三列是方差解释率，最后一列为𝜆取值。\n\n\n\n方法3 岭迹图主观选取",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#方程各系数",
    "href": "TCM/线性回归模型.html#方程各系数",
    "title": "线性回归模型",
    "section": "方程各系数",
    "text": "方程各系数\n\n\n   14 x 1 sparse Matrix of class \"dgCMatrix\"\n                        s1\n   (Intercept)  1.46961855\n   AKT1         0.10954607\n   PKC         -0.15147531\n   PIK3CA       0.10440970\n   PDE5        -0.22758172\n   AMPK        -0.11010478\n   eNOS        -0.21918436\n   SIRT1        0.18337012\n   PDK1         0.04530627\n   PRKG1       -0.09202807\n   APLNR       -0.21150215\n   TGR5         0.19878027\n   EDNRB       -0.10397655\n   CYP1A1      -0.02689341\n\n\n\n&gt; plot(ridge,xvar=\"dev\",label = T)#解释偏差的程度和回归系数的关系",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#拟合效果评价",
    "href": "TCM/线性回归模型.html#拟合效果评价",
    "title": "线性回归模型",
    "section": "拟合效果评价",
    "text": "拟合效果评价\n\n&gt; #拟合值\n&gt; ridge.y&lt;- predict(ridge,newx=x,s=0.03,type = \"response\")\n&gt; plot(ridge.y,y,xlab=\"Predicted\",ylab = \"Actual\",main = \"Ridge Regression\")#预测点在y=x的线上上下波动，表明拟合效果较好。\n\n\n\n\n\n\n\n&gt; # 理想情况下，真实值和预测值是相等的（即y=x）",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#岭回归的r2值和均方误差mse的值",
    "href": "TCM/线性回归模型.html#岭回归的r2值和均方误差mse的值",
    "title": "线性回归模型",
    "section": "岭回归的R2值和均方误差MSE的值",
    "text": "岭回归的R2值和均方误差MSE的值\n\n\n   Mean Squared Error (MSE): 1.288113 \n   R Squared (rsq): 0.1820842\n\n\n岭回归可以提升模型的拟合程度R2，一定程度上解决变量之间的共线性问题，但是无法大幅提升模型的拟合程度，说明模型拟合程度不高的根本原因，不仅仅是变量之间的共线性，还有其他的因素，例如变量的方差过大。\n均方误差的值，在一定程度上体现了变量的变异程度较大。使得模型的线性关系不稳定。接下来我们将分种类构建，不同种类的蛋白化合物与13个靶点蛋白的结合能对log10ec50的回归预测模型。",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#全部变量线性回归",
    "href": "TCM/线性回归模型.html#全部变量线性回归",
    "title": "线性回归模型",
    "section": "全部变量线性回归",
    "text": "全部变量线性回归\n\n&gt; library(easystats)\n&gt; model &lt;- lm(log10ec50 ~.-ec50,data = Flavonoids)\n&gt;   summary(model)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ . - ec50, data = Flavonoids)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -0.71490 -0.31584  0.03926  0.21504  0.69502 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)  10.6812     3.1996   3.338 0.004492 ** \n   AKT1         -0.1145     0.4619  -0.248 0.807661    \n   PKC           0.4701     0.2156   2.180 0.045600 *  \n   PIK3CA        0.7565     0.3114   2.429 0.028159 *  \n   PDE5          0.7903     0.2988   2.645 0.018384 *  \n   AMPK         -2.2291     0.6276  -3.552 0.002898 ** \n   eNOS          0.7679     0.5434   1.413 0.177984    \n   SIRT1        -0.2794     0.3171  -0.881 0.392089    \n   PDK1          1.3519     0.4878   2.772 0.014253 *  \n   PRKG1         0.4012     0.2568   1.563 0.138967    \n   APLNR        -2.0091     0.3867  -5.195 0.000109 ***\n   TGR5         -0.1906     0.3243  -0.588 0.565557    \n   EDNRB        -0.7499     0.4098  -1.830 0.087202 .  \n   CYP1A1       -0.2155     0.1513  -1.424 0.174932    \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.5422 on 15 degrees of freedom\n   Multiple R-squared:  0.8278, Adjusted R-squared:  0.6785 \n   F-statistic: 5.546 on 13 and 15 DF,  p-value: 0.001167\n\n\n\n&gt; y &lt;- Flavonoids[,15] |&gt;as.matrix()\n&gt; x &lt;- Flavonoids[,-c(15,14)] |&gt;\n+   as.matrix()\n\n\n&gt; # 预测\n&gt; predictions &lt;- predict(model, newdata = Flavonoids)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"Linear Regression MSE:\", mse_lm))\n\n   [1] \"Linear Regression MSE: 0.152061911817757\"\n\n&gt; print(paste(\"Linear Regression AIC:\", AIC(model)))\n\n   [1] \"Linear Regression AIC: 57.6778766580835\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#最优子集法筛选模型-1",
    "href": "TCM/线性回归模型.html#最优子集法筛选模型-1",
    "title": "线性回归模型",
    "section": "最优子集法筛选模型",
    "text": "最优子集法筛选模型\n\n&gt; model_final &lt;- model|&gt;\n+   select_parameters() \n&gt; summary(model_final)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ PKC + PIK3CA + PDE5 + AMPK + eNOS + \n       PDK1 + PRKG1 + APLNR + EDNRB + CYP1A1, data = Flavonoids)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -0.87577 -0.30203  0.04005  0.39952  0.68372 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)   9.9965     2.6347   3.794 0.001329 ** \n   PKC           0.4268     0.1997   2.137 0.046587 *  \n   PIK3CA        0.6204     0.2586   2.399 0.027488 *  \n   PDE5          0.7417     0.2466   3.008 0.007557 ** \n   AMPK         -2.1547     0.5205  -4.140 0.000615 ***\n   eNOS          0.5935     0.4484   1.324 0.202193    \n   PDK1          1.2893     0.4571   2.820 0.011329 *  \n   PRKG1         0.4015     0.2386   1.682 0.109748    \n   APLNR        -1.9399     0.3396  -5.713 2.04e-05 ***\n   EDNRB        -0.9412     0.3250  -2.896 0.009625 ** \n   CYP1A1       -0.2101     0.1001  -2.099 0.050230 .  \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.5175 on 18 degrees of freedom\n   Multiple R-squared:  0.8117, Adjusted R-squared:  0.7071 \n   F-statistic: 7.761 on 10 and 18 DF,  p-value: 0.0001014\n\n\n\n&gt; predictions &lt;- predict(model_final, newdata = Flavonoids)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"最优子集模型 MSE:\", mse_lm))\n\n   [1] \"最优子集模型 MSE: 0.166240947980718\"\n\n&gt; print(paste(\"最优子集模型 AIC:\", AIC(model_final)))\n\n   [1] \"最优子集模型 AIC: 54.2632405000913\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#模型诊断",
    "href": "TCM/线性回归模型.html#模型诊断",
    "title": "线性回归模型",
    "section": "模型诊断",
    "text": "模型诊断\n\n&gt; library(YangPac)\n&gt; ModelDiagnose(model_final)\n\n   [1] \"------------------正态性检验--------------------\"\n   OK: residuals appear as normally distributed (p = 0.061).\n   \n   [1] \"-----------异方差性（方差齐性）检验---------------\"\n   OK: Error variance appears to be homoscedastic (p = 0.312).\n   \n   [1] \"----------------自相关性检验--------------------\"\n   OK: Residuals appear to be independent and not autocorrelated (p = 0.530).\n   \n   [1] \"-----------多重共线性性检验---------------\"\n   # Check for Multicollinearity\n   \n   Low Correlation\n   \n      Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n       PKC 2.36 [ 1.78,  3.37]         1.54      0.42     [0.30, 0.56]\n    PIK3CA 4.42 [ 3.15,  6.45]         2.10      0.23     [0.16, 0.32]\n      PDE5 4.97 [ 3.51,  7.28]         2.23      0.20     [0.14, 0.28]\n     PRKG1 1.97 [ 1.52,  2.79]         1.40      0.51     [0.36, 0.66]\n    CYP1A1 4.26 [ 3.04,  6.21]         2.06      0.23     [0.16, 0.33]\n   \n   Moderate Correlation\n   \n     Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     AMPK 8.70 [ 5.99, 12.87]         2.95      0.11     [0.08, 0.17]\n    APLNR 6.54 [ 4.55,  9.62]         2.56      0.15     [0.10, 0.22]\n    EDNRB 8.05 [ 5.56, 11.90]         2.84      0.12     [0.08, 0.18]\n   \n   High Correlation\n   \n    Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    eNOS 20.28 [13.71, 30.26]         4.50      0.05     [0.03, 0.07]\n    PDK1 14.20 [ 9.66, 21.12]         3.77      0.07     [0.05, 0.10]",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#岭回归-1",
    "href": "TCM/线性回归模型.html#岭回归-1",
    "title": "线性回归模型",
    "section": "岭回归",
    "text": "岭回归\n\n方程各系数\n\n\n   14 x 1 sparse Matrix of class \"dgCMatrix\"\n                        s1\n   (Intercept)  5.82005794\n   AKT1        -0.30101576\n   PKC          0.42549417\n   PIK3CA       0.62300752\n   PDE5         0.57819308\n   AMPK        -1.00340963\n   eNOS         0.13126786\n   SIRT1       -0.05636896\n   PDK1         0.57365719\n   PRKG1        0.20635375\n   APLNR       -1.28264565\n   TGR5        -0.02791703\n   EDNRB       -0.34596150\n   CYP1A1      -0.20431364\n\n\n\n&gt; ridge.y&lt;- predict(ridge,newx=x,s=0.035,type = \"response\") \n&gt; plot(ridge.y,y,xlab=\"Predicted\",ylab = \"Actual\",main = \"Ridge Regression\")\n\n\n\n\n\n\n\n\n\n\n岭回归的R2值和均方误差(MSE)\n\n&gt; R2_mse(Flavonoids,ridge,0.0035)\n\n   Mean Squared Error (MSE): 0.212761 \n   R Squared (rsq): 0.7590446",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#全部指标建模",
    "href": "TCM/线性回归模型.html#全部指标建模",
    "title": "线性回归模型",
    "section": "全部指标建模",
    "text": "全部指标建模\n多元R2值较高，调整后的R2值0.09，差距较大，P值0.5&gt;0.05，方程解释程度较小，说明该种蛋白化合物数据各个自变量之间的共线性影响较为严重。\n\n&gt; model &lt;- lm(log10ec50~.-ec50,data = saponin)\n&gt;   summary(model)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ . - ec50, data = saponin)\n   \n   Residuals:\n           1         2         3         4         5         6         7         8 \n   -0.147787  0.538207  0.725845  0.906822 -0.003582  0.258288  0.844916 -0.028152 \n           9        10        11        12        13        14        15        16 \n   -0.194170 -1.274131 -0.802024 -0.025112  0.304528 -1.572631  0.456686  0.260566 \n          17 \n   -0.248268 \n   \n   Coefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n   (Intercept) -10.99950   16.12040  -0.682    0.544\n   AKT1          0.14205    1.10368   0.129    0.906\n   PKC          -2.81219    1.24063  -2.267    0.108\n   PIK3CA        2.34133    1.52878   1.532    0.223\n   PDE5         -1.62499    0.92723  -1.753    0.178\n   AMPK         -0.33138    1.56407  -0.212    0.846\n   eNOS          0.12290    0.86885   0.141    0.896\n   SIRT1         0.04535    1.53406   0.030    0.978\n   PDK1          0.49772    1.02797   0.484    0.661\n   PRKG1        -0.61160    1.51218  -0.404    0.713\n   APLNR         1.12437    5.41104   0.208    0.849\n   TGR5          0.33007    1.02006   0.324    0.768\n   EDNRB         1.67705    3.18247   0.527    0.635\n   CYP1A1        0.29971    2.26942   0.132    0.903\n   \n   Residual standard error: 1.597 on 3 degrees of freedom\n   Multiple R-squared:   0.83,  Adjusted R-squared:  0.09307 \n   F-statistic: 1.126 on 13 and 3 DF,  p-value: 0.5269\n\n\n\n&gt; # 预测\n&gt; predictions &lt;- predict(model, newdata = saponin)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"Linear Regression MSE:\", mse_lm))\n\n   [1] \"Linear Regression MSE: 0.450063010837608\"\n\n&gt; print(paste(\"Linear Regression AIC:\", AIC(model)))\n\n   [1] \"Linear Regression AIC: 64.6716595360358\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#最优子集筛选",
    "href": "TCM/线性回归模型.html#最优子集筛选",
    "title": "线性回归模型",
    "section": "最优子集筛选",
    "text": "最优子集筛选\n减少共线性较高的预测变量，R2显著提升。\n\n\n   \n   Call:\n   lm(formula = log10ec50 ~ PKC + PIK3CA + PDE5 + EDNRB + CYP1A1, \n       data = saponin)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -1.61958 -0.40345  0.03593  0.60166  1.00880 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)  -2.3507     3.5738  -0.658 0.524219    \n   PKC          -2.4697     0.5838  -4.230 0.001412 ** \n   PIK3CA        2.0240     0.6088   3.324 0.006778 ** \n   PDE5         -1.8261     0.4366  -4.182 0.001530 ** \n   EDNRB         1.9591     0.4185   4.681 0.000671 ***\n   CYP1A1        0.8466     0.6461   1.310 0.216795    \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.9304 on 11 degrees of freedom\n   Multiple R-squared:  0.7884, Adjusted R-squared:  0.6922 \n   F-statistic: 8.195 on 5 and 11 DF,  p-value: 0.001914\n\n\n\n&gt; predictions &lt;- predict(model_final, newdata = saponin)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"最优子集模型 MSE:\", mse_lm))\n\n   [1] \"最优子集模型 MSE: 0.560112328519279\"\n\n&gt; print(paste(\"最优子集模型 AIC:\", AIC(model_final)))\n\n   [1] \"最优子集模型 AIC: 52.3904053406138\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#岭回归-2",
    "href": "TCM/线性回归模型.html#岭回归-2",
    "title": "线性回归模型",
    "section": "岭回归",
    "text": "岭回归\n\n绘制岭回归的残差图\n\n&gt; ridge_predictions &lt;- predict(ridge, s = 0.06, newx = x) \n\n\n\n岭回归的R2值和均方误差(MSE)\n\n&gt; R2_mse(saponin,ridge,0.06)\n\n   Mean Squared Error (MSE): 0.5072452 \n   R Squared (rsq): 0.8083448\n\n\n\n\n方程各系数\n\n\n   14 x 1 sparse Matrix of class \"dgCMatrix\"\n                        s1\n   (Intercept) -5.80016357\n   AKT1         0.15246982\n   PKC         -2.27542860\n   PIK3CA       1.80981631\n   PDE5        -1.45483710\n   AMPK        -0.36769201\n   eNOS        -0.04041883\n   SIRT1        0.08215439\n   PDK1         0.30011879\n   PRKG1       -0.26699522\n   APLNR        0.77257334\n   TGR5         0.22078822\n   EDNRB        1.40263720\n   CYP1A1       0.40334906",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#全部变量线性回归-1",
    "href": "TCM/线性回归模型.html#全部变量线性回归-1",
    "title": "线性回归模型",
    "section": "全部变量线性回归",
    "text": "全部变量线性回归\n\n&gt; library(easystats)\n&gt; model &lt;- lm(log10ec50 ~.-ec50,data = Alkaloids)\n&gt;   summary(model)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ . - ec50, data = Alkaloids)\n   \n   Residuals:\n          1        2        3        4        5        6        7        8 \n   -0.22870 -0.05617  0.08248  0.00418  0.23730  0.77080  0.16152 -0.03024 \n          9       10       11       12       13       14       15       16 \n   -0.27326 -0.09633  0.91456 -0.71988  0.02231 -0.03806  0.09489 -0.65962 \n         17       18       19 \n   -0.22768  0.12982 -0.08790 \n   \n   Coefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)   \n   (Intercept)  8.979773   1.768127   5.079  0.00384 **\n   AKT1        -1.405575   0.541231  -2.597  0.04843 * \n   PKC         -0.493047   0.394269  -1.251  0.26644   \n   PIK3CA       1.710560   0.910508   1.879  0.11908   \n   PDE5        -0.262127   0.509827  -0.514  0.62906   \n   AMPK         5.054500   1.221126   4.139  0.00900 **\n   eNOS         1.994357   0.825621   2.416  0.06045 . \n   SIRT1       -1.682406   0.747363  -2.251  0.07417 . \n   PDK1        -2.437268   0.873204  -2.791  0.03839 * \n   PRKG1        0.001883   0.441152   0.004  0.99676   \n   APLNR       -2.021380   0.560771  -3.605  0.01547 * \n   TGR5        -3.580033   0.807179  -4.435  0.00679 **\n   EDNRB        3.054451   0.973256   3.138  0.02571 * \n   CYP1A1      -0.585859   0.216382  -2.708  0.04240 * \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.735 on 5 degrees of freedom\n   Multiple R-squared:  0.9346, Adjusted R-squared:  0.7646 \n   F-statistic: 5.498 on 13 and 5 DF,  p-value: 0.03551\n\n\n\n&gt; y &lt;- Alkaloids[,15] |&gt;as.matrix()\n&gt; x &lt;- Alkaloids[,-c(15,14)] |&gt;\n+   as.matrix()\n\n\n&gt; # 预测\n&gt; predictions &lt;- predict(model, newdata = Alkaloids)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"Linear Regression MSE:\", mse_lm))\n\n   [1] \"Linear Regression MSE: 0.142146566757345\"\n\n&gt; print(paste(\"Linear Regression AIC:\", AIC(model)))\n\n   [1] \"Linear Regression AIC: 46.8526289866258\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#最优子集法筛选模型-2",
    "href": "TCM/线性回归模型.html#最优子集法筛选模型-2",
    "title": "线性回归模型",
    "section": "最优子集法筛选模型",
    "text": "最优子集法筛选模型\n\n&gt; model_final &lt;- model|&gt;\n+   select_parameters() \n&gt; summary(model_final)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ AKT1 + PKC + PIK3CA + AMPK + eNOS + \n       SIRT1 + PDK1 + APLNR + TGR5 + EDNRB + CYP1A1, data = Alkaloids)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -0.71649 -0.18286 -0.02158  0.10397  0.89768 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)   9.3125     1.2875   7.233 0.000172 ***\n   AKT1         -1.4368     0.4664  -3.081 0.017793 *  \n   PKC          -0.4251     0.3221  -1.320 0.228400    \n   PIK3CA        1.6697     0.7791   2.143 0.069307 .  \n   AMPK          5.3204     0.9535   5.580 0.000833 ***\n   eNOS          2.0715     0.6891   3.006 0.019777 *  \n   SIRT1        -1.9127     0.5186  -3.688 0.007773 ** \n   PDK1         -2.7201     0.5867  -4.636 0.002380 ** \n   APLNR        -2.1900     0.3618  -6.052 0.000515 ***\n   TGR5         -3.6477     0.6793  -5.370 0.001041 ** \n   EDNRB         3.2365     0.7558   4.282 0.003646 ** \n   CYP1A1       -0.6385     0.1637  -3.901 0.005890 ** \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.6374 on 7 degrees of freedom\n   Multiple R-squared:  0.9312, Adjusted R-squared:  0.823 \n   F-statistic: 8.606 on 11 and 7 DF,  p-value: 0.004433\n\n\n\n&gt; predictions &lt;- predict(model_final, newdata = Alkaloids)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"最优子集模型 MSE:\", mse_lm))\n\n   [1] \"最优子集模型 MSE: 0.149676023017795\"\n\n&gt; print(paste(\"最优子集模型 AIC:\", AIC(model_final)))\n\n   [1] \"最优子集模型 AIC: 43.8333030837152\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#模型诊断-1",
    "href": "TCM/线性回归模型.html#模型诊断-1",
    "title": "线性回归模型",
    "section": "模型诊断",
    "text": "模型诊断\n\n&gt; library(YangPac)\n&gt; ModelDiagnose(model_final)\n\n   [1] \"------------------正态性检验--------------------\"\n   OK: residuals appear as normally distributed (p = 0.813).\n   \n   [1] \"-----------异方差性（方差齐性）检验---------------\"\n   OK: Error variance appears to be homoscedastic (p = 0.715).\n   \n   [1] \"----------------自相关性检验--------------------\"\n   OK: Residuals appear to be independent and not autocorrelated (p = 0.658).\n   \n   [1] \"-----------多重共线性性检验---------------\"\n   # Check for Multicollinearity\n   \n   Low Correlation\n   \n      Term  VIF      VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n      AKT1 4.56 [ 3.63,   5.81]         2.13      0.22     [0.17, 0.28]\n    CYP1A1 3.64 [ 2.93,   4.61]         1.91      0.27     [0.22, 0.34]\n   \n   Moderate Correlation\n   \n    Term  VIF      VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     PKC 7.39 [ 5.81,   9.50]         2.72      0.14     [0.11, 0.17]\n   \n   High Correlation\n   \n      Term   VIF      VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    PIK3CA 31.12 [24.03,  40.41]         5.58      0.03     [0.02, 0.04]\n      AMPK 87.23 [67.11, 113.49]         9.34      0.01     [0.01, 0.01]\n      eNOS 34.93 [26.95,  45.37]         5.91      0.03     [0.02, 0.04]\n     SIRT1 29.42 [22.72,  38.19]         5.42      0.03     [0.03, 0.04]\n      PDK1 32.51 [25.09,  42.21]         5.70      0.03     [0.02, 0.04]\n     APLNR 10.02 [ 7.82,  12.92]         3.16      0.10     [0.08, 0.13]\n      TGR5 44.60 [34.37,  57.96]         6.68      0.02     [0.02, 0.03]\n     EDNRB 36.15 [27.89,  46.96]         6.01      0.03     [0.02, 0.04]",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#岭回归-3",
    "href": "TCM/线性回归模型.html#岭回归-3",
    "title": "线性回归模型",
    "section": "岭回归",
    "text": "岭回归\n\n方程各系数\n\n\n   14 x 1 sparse Matrix of class \"dgCMatrix\"\n                         s1\n   (Intercept)  6.435581710\n   AKT1        -0.540288095\n   PKC         -0.458524565\n   PIK3CA       0.669129083\n   PDE5        -0.536427507\n   AMPK         0.505480672\n   eNOS         0.343311284\n   SIRT1       -0.006730424\n   PDK1        -0.076345041\n   PRKG1        0.417289584\n   APLNR       -0.522959611\n   TGR5        -0.350342785\n   EDNRB       -0.085139571\n   CYP1A1      -0.082836867\n\n\n\n&gt; ridge.y&lt;- predict(ridge,newx=x,s=0.09,type = \"response\") \n&gt; plot(ridge.y,y,xlab=\"Predicted\",ylab = \"Actual\",main = \"Ridge Regression\")\n\n\n\n\n\n\n\n\n\n\n岭回归的R2值和均方误差(MSE)\n\n&gt; R2_mse(saponin,ridge,0.06)\n\n   Mean Squared Error (MSE): 7.314633 \n   R Squared (rsq): -1.763727",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#全部变量线性回归-2",
    "href": "TCM/线性回归模型.html#全部变量线性回归-2",
    "title": "线性回归模型",
    "section": "全部变量线性回归",
    "text": "全部变量线性回归\n\n&gt; library(easystats)\n&gt; model &lt;- lm(log10ec50 ~.-ec50,data = Phenols)\n&gt;   summary(model)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ . - ec50, data = Phenols)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -1.55554 -0.33751  0.06419  0.40981  1.44722 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)  \n   (Intercept)  6.95623    2.74716   2.532   0.0215 *\n   AKT1         0.19426    0.46694   0.416   0.6826  \n   PKC          0.19205    1.05198   0.183   0.8573  \n   PIK3CA       0.76591    0.37047   2.067   0.0543 .\n   PDE5        -0.08661    0.93411  -0.093   0.9272  \n   AMPK        -1.29362    1.18806  -1.089   0.2914  \n   eNOS        -0.41441    0.31157  -1.330   0.2011  \n   SIRT1        0.47075    0.73481   0.641   0.5303  \n   PDK1         0.03435    0.28716   0.120   0.9062  \n   PRKG1        0.63178    0.90657   0.697   0.4953  \n   APLNR        0.57676    0.88004   0.655   0.5210  \n   TGR5         0.18157    0.76449   0.238   0.8151  \n   EDNRB       -1.41274    0.50769  -2.783   0.0128 *\n   CYP1A1      -0.56269    0.33189  -1.695   0.1082  \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.8919 on 17 degrees of freedom\n   Multiple R-squared:  0.776,  Adjusted R-squared:  0.6048 \n   F-statistic: 4.531 on 13 and 17 DF,  p-value: 0.002243\n\n\n\n&gt; y &lt;- Phenols[,15] |&gt;as.matrix()\n&gt; x &lt;- Phenols[,-c(15,14)] |&gt;\n+   as.matrix()\n\n\n&gt; # 预测\n&gt; predictions &lt;- predict(model, newdata = Phenols)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"Linear Regression MSE:\", mse_lm))\n\n   [1] \"Linear Regression MSE: 0.436262622034652\"\n\n&gt; print(paste(\"Linear Regression AIC:\", AIC(model)))\n\n   [1] \"Linear Regression AIC: 92.2593520002365\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#最优子集法筛选模型-3",
    "href": "TCM/线性回归模型.html#最优子集法筛选模型-3",
    "title": "线性回归模型",
    "section": "最优子集法筛选模型",
    "text": "最优子集法筛选模型\n\n&gt; model_final &lt;- model|&gt;\n+   select_parameters() \n&gt; summary(model_final)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ PIK3CA + AMPK + eNOS + PRKG1 + EDNRB + \n       CYP1A1, data = Phenols)\n   \n   Residuals:\n       Min      1Q  Median      3Q     Max \n   -1.7548 -0.4704  0.1094  0.5838  1.2678 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)   7.6888     1.6200   4.746 7.92e-05 ***\n   PIK3CA        1.0418     0.2509   4.152 0.000359 ***\n   AMPK         -0.5965     0.3646  -1.636 0.114855    \n   eNOS         -0.3157     0.1869  -1.689 0.104077    \n   PRKG1         0.7528     0.5022   1.499 0.146878    \n   EDNRB        -1.0890     0.3137  -3.472 0.001975 ** \n   CYP1A1       -0.5733     0.1605  -3.573 0.001538 ** \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.8017 on 24 degrees of freedom\n   Multiple R-squared:  0.7446, Adjusted R-squared:  0.6807 \n   F-statistic: 11.66 on 6 and 24 DF,  p-value: 4.103e-06\n\n\n\n&gt; predictions &lt;- predict(model_final, newdata = Phenols)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"最优子集模型 MSE:\", mse_lm))\n\n   [1] \"最优子集模型 MSE: 0.497575759203293\"\n\n&gt; print(paste(\"最优子集模型 AIC:\", AIC(model_final)))\n\n   [1] \"最优子集模型 AIC: 82.3359579793805\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#模型诊断-2",
    "href": "TCM/线性回归模型.html#模型诊断-2",
    "title": "线性回归模型",
    "section": "模型诊断",
    "text": "模型诊断\n\n&gt; ModelDiagnose(model_final)\n\n   [1] \"------------------正态性检验--------------------\"\n   OK: residuals appear as normally distributed (p = 0.320).\n   \n   [1] \"-----------异方差性（方差齐性）检验---------------\"\n   OK: Error variance appears to be homoscedastic (p = 0.095).\n   \n   [1] \"----------------自相关性检验--------------------\"\n   OK: Residuals appear to be independent and not autocorrelated (p = 0.576).\n   \n   [1] \"-----------多重共线性性检验---------------\"\n   # Check for Multicollinearity\n   \n   Low Correlation\n   \n      Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    PIK3CA 4.42 [2.93,  7.05]         2.10      0.23     [0.14, 0.34]\n      eNOS 3.11 [2.14,  4.91]         1.76      0.32     [0.20, 0.47]\n    CYP1A1 2.59 [1.83,  4.07]         1.61      0.39     [0.25, 0.55]\n   \n   Moderate Correlation\n   \n     Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     AMPK 8.81 [5.59, 14.29]         2.97      0.11     [0.07, 0.18]\n    PRKG1 6.50 [4.19, 10.47]         2.55      0.15     [0.10, 0.24]\n    EDNRB 9.05 [5.74, 14.68]         3.01      0.11     [0.07, 0.17]",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#岭回归-4",
    "href": "TCM/线性回归模型.html#岭回归-4",
    "title": "线性回归模型",
    "section": "岭回归",
    "text": "岭回归\n\n方程各系数\n\n\n   14 x 1 sparse Matrix of class \"dgCMatrix\"\n                        s1\n   (Intercept)  7.12931973\n   AKT1         0.26253932\n   PKC         -0.15700302\n   PIK3CA       0.57004454\n   PDE5        -0.20227936\n   AMPK        -0.40062493\n   eNOS        -0.10801234\n   SIRT1        0.14769923\n   PDK1        -0.03027368\n   PRKG1        0.01921076\n   APLNR       -0.05202150\n   TGR5         0.15570623\n   EDNRB       -0.60463582\n   CYP1A1      -0.30786379\n\n\n\n&gt; ridge.y&lt;- predict(ridge,newx=x,s=0.08,type = \"response\") \n&gt; plot(ridge.y,y,xlab=\"Predicted\",ylab = \"Actual\",main = \"Ridge Regression\")\n\n\n\n\n\n\n\n\n\n\n岭回归的R2值和均方误差(MSE)\n\n&gt; R2_mse(saponin,ridge,0.06)\n\n   Mean Squared Error (MSE): 2.998338 \n   R Squared (rsq): -0.1328781",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#全部变量线性回归-3",
    "href": "TCM/线性回归模型.html#全部变量线性回归-3",
    "title": "线性回归模型",
    "section": "全部变量线性回归",
    "text": "全部变量线性回归\n\n&gt; library(easystats)\n&gt; model &lt;- lm(log10ec50 ~.-ec50,data = Terpenes)\n&gt;   summary(model)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ . - ec50, data = Terpenes)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -1.11342 -0.30168 -0.03678  0.39141  1.23530 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)  \n   (Intercept)  6.42265    3.15097   2.038    0.072 .\n   AKT1         0.43593    1.04047   0.419    0.685  \n   PKC          0.37031    0.58965   0.628    0.546  \n   PIK3CA      -0.79807    0.74685  -1.069    0.313  \n   PDE5        -0.10249    0.67879  -0.151    0.883  \n   AMPK         0.21174    0.79779   0.265    0.797  \n   eNOS        -0.13011    0.67498  -0.193    0.851  \n   SIRT1       -0.16271    0.64037  -0.254    0.805  \n   PDK1        -0.74526    1.03781  -0.718    0.491  \n   PRKG1        0.32773    0.90067   0.364    0.724  \n   APLNR        0.06236    0.58584   0.106    0.918  \n   TGR5         0.42533    0.30342   1.402    0.195  \n   EDNRB       -0.65244    0.89666  -0.728    0.485  \n   CYP1A1       0.23733    0.19546   1.214    0.256  \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.8641 on 9 degrees of freedom\n   Multiple R-squared:  0.7616, Adjusted R-squared:  0.4172 \n   F-statistic: 2.212 on 13 and 9 DF,  p-value: 0.1182\n\n\n\n&gt; y &lt;- Terpenes[,15] |&gt;as.matrix()\n&gt; x &lt;- Terpenes[,-c(15,14)] |&gt;\n+   as.matrix()\n\n\n&gt; # 预测\n&gt; predictions &lt;- predict(model, newdata = Terpenes)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"Linear Regression MSE:\", mse_lm))\n\n   [1] \"Linear Regression MSE: 0.292204688288982\"\n\n&gt; print(paste(\"Linear Regression AIC:\", AIC(model)))\n\n   [1] \"Linear Regression AIC: 66.9742556224229\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#最优子集法筛选模型-4",
    "href": "TCM/线性回归模型.html#最优子集法筛选模型-4",
    "title": "线性回归模型",
    "section": "最优子集法筛选模型",
    "text": "最优子集法筛选模型\n\n&gt; model_final &lt;- model|&gt;\n+   select_parameters() \n&gt; summary(model_final)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ PIK3CA + TGR5 + EDNRB + CYP1A1, data = Terpenes)\n   \n   Residuals:\n        Min       1Q   Median       3Q      Max \n   -1.14232 -0.33739 -0.04902  0.51403  1.17568 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)  7.81045    1.27160   6.142 8.43e-06 ***\n   PIK3CA      -0.60720    0.37963  -1.599  0.12713    \n   TGR5         0.56378    0.15831   3.561  0.00223 ** \n   EDNRB       -1.05849    0.27446  -3.857  0.00116 ** \n   CYP1A1       0.15564    0.09034   1.723  0.10205    \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.6769 on 18 degrees of freedom\n   Multiple R-squared:  0.7074, Adjusted R-squared:  0.6424 \n   F-statistic: 10.88 on 4 and 18 DF,  p-value: 0.0001158\n\n\n\n&gt; predictions &lt;- predict(model_final, newdata = Terpenes)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"最优子集模型 MSE:\", mse_lm))\n\n   [1] \"最优子集模型 MSE: 0.358619673022883\"\n\n&gt; print(paste(\"最优子集模型 AIC:\", AIC(model_final)))\n\n   [1] \"最优子集模型 AIC: 53.6848367777012\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#模型诊断-3",
    "href": "TCM/线性回归模型.html#模型诊断-3",
    "title": "线性回归模型",
    "section": "模型诊断",
    "text": "模型诊断\n\n&gt; library(YangPac)\n&gt; ModelDiagnose(model)\n\n   [1] \"------------------正态性检验--------------------\"\n   OK: residuals appear as normally distributed (p = 0.897).\n   \n   [1] \"-----------异方差性（方差齐性）检验---------------\"\n   OK: Error variance appears to be homoscedastic (p = 0.455).\n   \n   [1] \"----------------自相关性检验--------------------\"\n   OK: Residuals appear to be independent and not autocorrelated (p = 0.474).\n   \n   [1] \"-----------多重共线性性检验---------------\"\n   # Check for Multicollinearity\n   \n   Low Correlation\n   \n      Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    CYP1A1 3.28 [ 2.64,  4.16]         1.81      0.30     [0.24, 0.38]\n   \n   Moderate Correlation\n   \n    Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     PKC 8.90 [ 6.94, 11.50]         2.98      0.11     [0.09, 0.14]\n    TGR5 7.75 [ 6.06,  9.99]         2.78      0.13     [0.10, 0.16]\n   \n   High Correlation\n   \n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n      AKT1 21.04 [16.23, 27.37]         4.59      0.05     [0.04, 0.06]\n    PIK3CA 13.36 [10.36, 17.33]         3.66      0.07     [0.06, 0.10]\n      PDE5 13.23 [10.26, 17.16]         3.64      0.08     [0.06, 0.10]\n      AMPK 18.91 [14.60, 24.59]         4.35      0.05     [0.04, 0.07]\n      eNOS 27.75 [21.37, 36.13]         5.27      0.04     [0.03, 0.05]\n     SIRT1 14.87 [11.51, 19.30]         3.86      0.07     [0.05, 0.09]\n      PDK1 38.34 [29.47, 49.97]         6.19      0.03     [0.02, 0.03]\n     PRKG1 23.59 [18.19, 30.70]         4.86      0.04     [0.03, 0.05]\n     APLNR 10.97 [ 8.52, 14.20]         3.31      0.09     [0.07, 0.12]\n     EDNRB 26.12 [20.12, 34.00]         5.11      0.04     [0.03, 0.05]\n\n\n\n\n\n\n\n\n&gt; ModelDiagnose(model_final)\n\n   [1] \"------------------正态性检验--------------------\"\n   OK: residuals appear as normally distributed (p = 0.546).\n   \n   [1] \"-----------异方差性（方差齐性）检验---------------\"\n   OK: Error variance appears to be homoscedastic (p = 0.602).\n   \n   [1] \"----------------自相关性检验--------------------\"\n   OK: Residuals appear to be independent and not autocorrelated (p = 0.934).\n   \n   [1] \"-----------多重共线性性检验---------------\"\n   # Check for Multicollinearity\n   \n   Low Correlation\n   \n      Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n      TGR5 3.44 [2.23, 5.84]         1.85      0.29     [0.17, 0.45]\n     EDNRB 3.99 [2.54, 6.80]         2.00      0.25     [0.15, 0.39]\n    CYP1A1 1.14 [1.01, 2.86]         1.07      0.88     [0.35, 0.99]\n   \n   Moderate Correlation\n   \n      Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    PIK3CA 5.63 [3.46, 9.69]         2.37      0.18     [0.10, 0.29]",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#岭回归-5",
    "href": "TCM/线性回归模型.html#岭回归-5",
    "title": "线性回归模型",
    "section": "岭回归",
    "text": "岭回归\n\n方程各系数\n\n\n   14 x 1 sparse Matrix of class \"dgCMatrix\"\n                        s1\n   (Intercept)  6.20296901\n   AKT1        -0.02653323\n   PKC          0.20890259\n   PIK3CA      -0.35666282\n   PDE5        -0.26533342\n   AMPK         0.27227387\n   eNOS        -0.15341890\n   SIRT1       -0.24715257\n   PDK1        -0.27831593\n   PRKG1        0.15715467\n   APLNR        0.04133084\n   TGR5         0.32892301\n   EDNRB       -0.46921138\n   CYP1A1       0.14785399\n\n\n\n&gt; ridge.y&lt;- predict(ridge,newx=x,s=0.08,type = \"response\") \n&gt; plot(ridge.y,y,xlab=\"Predicted\",ylab = \"Actual\",main = \"Ridge Regression\")\n\n\n\n\n\n\n\n\n\n\n岭回归的R2值和均方误差(MSE)\n\n&gt; R2_mse(saponin,ridge,0.06)\n\n   Mean Squared Error (MSE): 6.537455 \n   R Squared (rsq): -1.470082",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#全部变量线性回归-4",
    "href": "TCM/线性回归模型.html#全部变量线性回归-4",
    "title": "线性回归模型",
    "section": "全部变量线性回归",
    "text": "全部变量线性回归\n\n&gt; library(easystats)\n&gt; model &lt;- lm(log10ec50 ~.-ec50,data = PPP)\n&gt;   summary(model)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ . - ec50, data = PPP)\n   \n   Residuals:\n          1        2        3        4        5        6        7        8 \n    0.09947 -0.01529 -0.04740  0.10067 -0.15370  0.25298  0.05560 -0.11079 \n          9       10       11       12       13       14       15       16 \n    0.17997 -0.08865  0.02891 -0.04551 -0.01297  0.32123 -0.37153 -0.19300 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)\n   (Intercept)  8.62118    3.87907   2.222    0.156\n   AKT1        -0.11377    0.82150  -0.138    0.903\n   PKC          1.67834    0.87016   1.929    0.194\n   PIK3CA       0.78843    0.34309   2.298    0.148\n   PDE5         1.37764    2.09019   0.659    0.578\n   AMPK        -1.10888    1.14738  -0.966    0.436\n   eNOS        -1.25976    1.14771  -1.098    0.387\n   SIRT1        0.78556    1.24443   0.631    0.592\n   PDK1        -0.54365    0.87779  -0.619    0.599\n   PRKG1       -0.67026    0.55429  -1.209    0.350\n   APLNR       -1.61286    1.53617  -1.050    0.404\n   TGR5        -0.07792    0.68401  -0.114    0.920\n   EDNRB       -0.12536    0.96921  -0.129    0.909\n   CYP1A1      -0.34871    0.37482  -0.930    0.450\n   \n   Residual standard error: 0.4729 on 2 degrees of freedom\n   Multiple R-squared:  0.9764, Adjusted R-squared:  0.823 \n   F-statistic: 6.364 on 13 and 2 DF,  p-value: 0.1438\n\n\n\n&gt; y &lt;- PPP[,15] |&gt;as.matrix()\n&gt; x &lt;- PPP[,-c(15,14)] |&gt;\n+   as.matrix()\n\n\n&gt; # 预测\n&gt; predictions &lt;- predict(model, newdata = PPP)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"Linear Regression MSE:\", mse_lm))\n\n   [1] \"Linear Regression MSE: 0.0279559949980445\"\n\n&gt; print(paste(\"Linear Regression AIC:\", AIC(model)))\n\n   [1] \"Linear Regression AIC: 18.1720552659144\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#最优子集法筛选模型-5",
    "href": "TCM/线性回归模型.html#最优子集法筛选模型-5",
    "title": "线性回归模型",
    "section": "最优子集法筛选模型",
    "text": "最优子集法筛选模型\n\n&gt; model_final &lt;- model|&gt;\n+   select_parameters() \n&gt; summary(model_final)\n\n   \n   Call:\n   lm(formula = log10ec50 ~ PKC + PIK3CA + PDE5 + AMPK + eNOS + \n       SIRT1 + PDK1 + PRKG1 + APLNR + CYP1A1, data = PPP)\n   \n   Residuals:\n          1        2        3        4        5        6        7        8 \n    0.13619 -0.06556 -0.03404  0.12401 -0.20851  0.28587  0.07262 -0.12616 \n          9       10       11       12       13       14       15       16 \n    0.20872 -0.08635  0.05405 -0.04728 -0.05811  0.25824 -0.36115 -0.15256 \n   \n   Coefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)   8.3875     0.9888   8.483 0.000374 ***\n   PKC           1.6333     0.3221   5.071 0.003862 ** \n   PIK3CA        0.7545     0.1684   4.481 0.006512 ** \n   PDE5          1.1619     0.4240   2.740 0.040794 *  \n   AMPK         -1.1067     0.3483  -3.178 0.024605 *  \n   eNOS         -1.1325     0.4150  -2.729 0.041347 *  \n   SIRT1         0.8679     0.4094   2.120 0.087485 .  \n   PDK1         -0.6640     0.3459  -1.920 0.112934    \n   PRKG1        -0.7592     0.2690  -2.823 0.036986 *  \n   APLNR        -1.5906     0.3948  -4.029 0.010031 *  \n   CYP1A1       -0.3229     0.1148  -2.813 0.037398 *  \n   ---\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n   \n   Residual standard error: 0.3052 on 5 degrees of freedom\n   Multiple R-squared:  0.9754, Adjusted R-squared:  0.9263 \n   F-statistic: 19.84 on 10 and 5 DF,  p-value: 0.00207\n\n\n\n&gt; predictions &lt;- predict(model_final, newdata = PPP)\n&gt;  \n&gt; # 计算MSE\n&gt; mse_lm &lt;- mean((predictions - y)^2)\n&gt; print(paste(\"最优子集模型 MSE:\", mse_lm))\n\n   [1] \"最优子集模型 MSE: 0.0291077727762431\"\n\n&gt; print(paste(\"最优子集模型 AIC:\", AIC(model_final)))\n\n   [1] \"最优子集模型 AIC: 12.818032506418\"",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#模型诊断-4",
    "href": "TCM/线性回归模型.html#模型诊断-4",
    "title": "线性回归模型",
    "section": "模型诊断",
    "text": "模型诊断\n\n&gt; ModelDiagnose(model_final)\n\n   [1] \"------------------正态性检验--------------------\"\n   OK: residuals appear as normally distributed (p = 0.629).\n   \n   [1] \"-----------异方差性（方差齐性）检验---------------\"\n   OK: Error variance appears to be homoscedastic (p = 0.497).\n   \n   [1] \"----------------自相关性检验--------------------\"\n   OK: Residuals appear to be independent and not autocorrelated (p = 0.128).\n   \n   [1] \"-----------多重共线性性检验---------------\"\n   # Check for Multicollinearity\n   \n   Low Correlation\n   \n      Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    PIK3CA 4.11 [ 3.40,  5.04]         2.03      0.24     [0.20, 0.29]\n    CYP1A1 4.64 [ 3.82,  5.71]         2.15      0.22     [0.18, 0.26]\n   \n   Moderate Correlation\n   \n     Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    PRKG1 7.27 [ 5.92,  9.00]         2.70      0.14     [0.11, 0.17]\n   \n   High Correlation\n   \n     Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n      PKC 16.01 [12.90, 19.95]         4.00      0.06     [0.05, 0.08]\n     PDE5 43.44 [34.79, 54.31]         6.59      0.02     [0.02, 0.03]\n     AMPK 15.02 [12.10, 18.70]         3.88      0.07     [0.05, 0.08]\n     eNOS 26.80 [21.51, 33.46]         5.18      0.04     [0.03, 0.05]\n    SIRT1 27.60 [22.14, 34.46]         5.25      0.04     [0.03, 0.05]\n     PDK1 24.50 [19.67, 30.58]         4.95      0.04     [0.03, 0.05]\n    APLNR 16.74 [13.47, 20.85]         4.09      0.06     [0.05, 0.07]",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  },
  {
    "objectID": "TCM/线性回归模型.html#岭回归-6",
    "href": "TCM/线性回归模型.html#岭回归-6",
    "title": "线性回归模型",
    "section": "岭回归",
    "text": "岭回归\n\n方程各系数\n\n\n   14 x 1 sparse Matrix of class \"dgCMatrix\"\n                         s1\n   (Intercept)  6.479651909\n   AKT1         0.197872284\n   PKC          0.786253229\n   PIK3CA       0.655306427\n   PDE5        -0.007733551\n   AMPK        -0.495885362\n   eNOS        -0.386107774\n   SIRT1        0.649148347\n   PDK1        -0.215970674\n   PRKG1       -0.936822245\n   APLNR       -0.281275576\n   TGR5        -0.163466739\n   EDNRB       -0.226227772\n   CYP1A1      -0.332733627\n\n\n\n&gt; ridge.y&lt;- predict(ridge,newx=x,s=0.06,type = \"response\") \n&gt; plot(ridge.y,y,xlab=\"Predicted\",ylab = \"Actual\",main = \"Ridge Regression\")\n\n\n\n\n\n\n\n\n\n\n岭回归的R2值和均方误差(MSE)\n\n&gt; R2_mse(saponin,ridge,0.06)\n\n   Mean Squared Error (MSE): 3.929984 \n   R Squared (rsq): -0.4848868",
    "crumbs": [
      "中医药研究TCM",
      "线性回归模型"
    ]
  }
]